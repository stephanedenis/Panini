{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6019f8bc",
   "metadata": {},
   "source": [
    "# üöÄ Colab GPU Daemon - Solution 2: Hybrid Local Dev + Remote Exec\n",
    "\n",
    "**Objectif**: Ex√©cuter automatiquement des exp√©riences GPU depuis commits GitHub\n",
    "\n",
    "## üìã Workflow:\n",
    "1. **D√©velopper localement** dans VSCode avec Copilot\n",
    "2. **Commit + Push** vers branche `gpu-experiments`\n",
    "3. **Ce notebook d√©tecte** le nouveau commit\n",
    "4. **Ex√©cute exp√©riences** d√©finies dans `experiments.json`\n",
    "5. **Push r√©sultats** automatiquement\n",
    "\n",
    "## ‚úÖ Avantages:\n",
    "- ‚ú® D√©veloppement 100% local (VSCode + Copilot)\n",
    "- üîí Z√©ro SSH fragile\n",
    "- ‚ôªÔ∏è Async naturel\n",
    "- üì¶ Tout dans Git (reproductible)\n",
    "- üéØ Background execution sans interruption\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Important**: Ce notebook doit tourner en continu sur Colab Pro pour surveiller le repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1a5a7",
   "metadata": {},
   "source": [
    "## üîß √âtape 1: V√©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ccdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier GPU disponible\n",
    "!nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader\n",
    "\n",
    "# Test PyTorch\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241eb7b",
   "metadata": {},
   "source": [
    "## üì¶ √âtape 2: Mount Google Drive (Persistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997210ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive pour persister r√©sultats\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cr√©er dossier outputs dans Drive\n",
    "!mkdir -p /content/drive/MyDrive/panini_colab_outputs\n",
    "!mkdir -p /content/outputs\n",
    "\n",
    "# Symlink vers Drive\n",
    "!rm -f /content/outputs 2>/dev/null || true\n",
    "!ln -s /content/drive/MyDrive/panini_colab_outputs /content/outputs\n",
    "\n",
    "print(\"‚úÖ Google Drive mont√© et li√© √† /content/outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0954f64",
   "metadata": {},
   "source": [
    "## üîë √âtape 3: Configuration Git (pour push r√©sultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9edd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Git (remplacer par vos infos)\n",
    "!git config --global user.name \"Colab GPU Daemon\"\n",
    "!git config --global user.email \"colab@panini-gpu.local\"\n",
    "\n",
    "print(\"‚úÖ Git configur√© pour commits automatiques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6cc16",
   "metadata": {},
   "source": [
    "## üì• √âtape 4: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08cfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo Panini (branche gpu-experiments)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = \"https://github.com/stephanedenis/Panini.git\"\n",
    "BRANCH = \"gpu-experiments\"\n",
    "WORK_DIR = Path(\"/content/work\")\n",
    "\n",
    "# Remove existing si pr√©sent\n",
    "if WORK_DIR.exists():\n",
    "    !rm -rf {str(WORK_DIR)}\n",
    "\n",
    "# Clone\n",
    "!git clone -b {BRANCH} {REPO_URL} {str(WORK_DIR)}\n",
    "\n",
    "print(f\"‚úÖ Repo clon√© dans {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1cc90",
   "metadata": {},
   "source": [
    "## üìö √âtape 5: Installer D√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5667313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer requirements.txt si pr√©sent\n",
    "%cd /content/work\n",
    "\n",
    "req_file = Path(\"requirements.txt\")\n",
    "if req_file.exists():\n",
    "    print(\"üì¶ Installation des d√©pendances...\")\n",
    "    !pip install -r requirements.txt -q\n",
    "    print(\"‚úÖ D√©pendances install√©es\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Pas de requirements.txt trouv√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6769a2",
   "metadata": {},
   "source": [
    "## ü§ñ √âtape 6: Lancer le Daemon\n",
    "\n",
    "**‚ö†Ô∏è Important**: Cette cellule tourne ind√©finiment! Elle surveille le repo et ex√©cute les exp√©riences.\n",
    "\n",
    "**Pour arr√™ter**: Menu Runtime ‚Üí Interrupt execution (ou `Ctrl+M I`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancer le daemon Python\n",
    "%cd /content/work\n",
    "\n",
    "# Le script daemon est dans tools/colab_daemon_setup.py\n",
    "!python tools/colab_daemon_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfa3e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Monitoring (Cellules optionnelles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f276bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir le log du daemon\n",
    "!tail -50 /content/daemon.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir experiments.json actuel\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "exp_file = Path(\"/content/work/experiments.json\")\n",
    "if exp_file.exists():\n",
    "    with open(exp_file) as f:\n",
    "        experiments = json.load(f)\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"EXPERIMENTS STATUS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for exp in experiments:\n",
    "        name = exp.get('name', 'unknown')\n",
    "        status = exp.get('status', 'unknown')\n",
    "        duration = exp.get('duration', 0)\n",
    "        \n",
    "        icon = {'completed': '‚úÖ', 'failed': '‚ùå', 'pending': '‚è≥', \n",
    "                'timeout': '‚è±Ô∏è', 'error': 'üí•'}.get(status, '‚ùì')\n",
    "        \n",
    "        print(f\"{icon} {name}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "        if duration:\n",
    "            print(f\"   Duration: {duration:.1f}s\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Aucun fichier experiments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir les outputs g√©n√©r√©s\n",
    "!ls -lh /content/outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c89ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring GPU en temps r√©el\n",
    "import time\n",
    "\n",
    "print(\"üîç GPU Monitoring (Ctrl+C pour arr√™ter)\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        !nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu --format=csv,noheader\n",
    "        time.sleep(5)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚úã Monitoring arr√™t√©\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
