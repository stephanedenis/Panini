{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d631575d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/stephanedenis/PaniniFS-Research/blob/main/notebooks/colab_dhatu_robust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c34b82",
   "metadata": {},
   "source": [
    "# üöÄ DhƒÅtu Analysis - Robust Colab Version\n",
    "\n",
    "Version robuste qui g√®re les credentials GitHub proprement et √©vite les erreurs fatales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480528ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Setup robuste avec gestion d'erreurs\n",
    "import os, json, requests, time, subprocess\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def setup_git_safely():\n",
    "    \"\"\"Configuration Git s√©curis√©e\"\"\"\n",
    "    try:\n",
    "        # V√©rifier si d√©j√† configur√©\n",
    "        result = subprocess.run(['git', 'config', 'user.email'], capture_output=True, text=True)\n",
    "        if result.returncode != 0 or not result.stdout.strip():\n",
    "            # Configuration par d√©faut pour Colab\n",
    "            subprocess.run(['git', 'config', 'user.email', 'colab@research.panini'], check=True)\n",
    "            subprocess.run(['git', 'config', 'user.name', 'Colab Research'], check=True)\n",
    "            print(\"‚úÖ Git configur√© pour Colab\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Git d√©j√† configur√©: {result.stdout.strip()}\")\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Probl√®me configuration Git: {e}\")\n",
    "        return False\n",
    "\n",
    "def clone_or_pull_repo():\n",
    "    \"\"\"Clone ou pull du repository\"\"\"\n",
    "    REPO_URL = \"https://github.com/stephanedenis/PaniniFS-Research\"\n",
    "    \n",
    "    if not os.path.exists('PaniniFS-Research'):\n",
    "        print(\"üì• Clonage du repository...\")\n",
    "        !git clone $REPO_URL\n",
    "        os.chdir('PaniniFS-Research')\n",
    "    else:\n",
    "        print(\"üîÑ Mise √† jour du repository...\")\n",
    "        os.chdir('PaniniFS-Research')\n",
    "        try:\n",
    "            !git pull origin main\n",
    "            print(\"‚úÖ Repository mis √† jour\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Mise √† jour √©chou√©e, continuons avec la version locale\")\n",
    "\n",
    "# Configuration et clonage\n",
    "git_configured = setup_git_safely()\n",
    "clone_or_pull_repo()\n",
    "print(\"‚úÖ Setup termin√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Analyseur DhƒÅtu Robuste\n",
    "class RobustDhatuAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.dhatu_patterns = {\n",
    "            '‡§≠‡•Ç': r'‡§≠‡•Ç|bh≈´|bhuu|√™tre|being|exist',\n",
    "            '‡§ï‡•É': r'‡§ï‡•É|k·πõ|kri|faire|doing|make|create',\n",
    "            '‡§ó‡§Æ‡•ç': r'‡§ó‡§Æ‡•ç|gam|aller|going|move|motion',\n",
    "            '‡§¶‡§æ': r'‡§¶‡§æ|dƒÅ|daa|donner|giving|give|grant',\n",
    "            '‡§∏‡•ç‡§•‡§æ': r'‡§∏‡•ç‡§•‡§æ|sthƒÅ|sthaa|√™tre debout|standing|remain',\n",
    "            '‡§µ‡§¶‡•ç': r'‡§µ‡§¶‡•ç|vad|dire|speak|say|tell',\n",
    "            '‡§≤‡§≠‡•ç': r'‡§≤‡§≠‡•ç|labh|obtenir|obtain|get|receive',\n",
    "            '‡§™‡§æ': r'‡§™‡§æ|pƒÅ|paa|prot√©ger|protect|guard',\n",
    "            '‡§π‡§®‡•ç': r'‡§π‡§®‡•ç|han|tuer|kill|destroy'\n",
    "        }\n",
    "        self.results = []\n",
    "        self.stats = {\n",
    "            'start_time': datetime.now().isoformat(),\n",
    "            'total_docs': 0,\n",
    "            'total_matches': 0\n",
    "        }\n",
    "    \n",
    "    def analyze_text(self, text, source=\"unknown\"):\n",
    "        \"\"\"Analyse robuste d'un texte\"\"\"\n",
    "        matches = {}\n",
    "        try:\n",
    "            for dhatu, pattern in self.dhatu_patterns.items():\n",
    "                import re\n",
    "                count = len(re.findall(pattern, text, re.IGNORECASE))\n",
    "                if count > 0:\n",
    "                    matches[dhatu] = count\n",
    "            \n",
    "            result = {\n",
    "                'source': source,\n",
    "                'text_length': len(text),\n",
    "                'dhatu_matches': matches,\n",
    "                'total_matches': sum(matches.values()),\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'quality_score': self.calculate_quality(text, matches)\n",
    "            }\n",
    "            \n",
    "            self.results.append(result)\n",
    "            self.stats['total_docs'] += 1\n",
    "            self.stats['total_matches'] += result['total_matches']\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur analyse: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_quality(self, text, matches):\n",
    "        \"\"\"Calcul de qualit√© du document\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Bonus longueur\n",
    "        if 100 <= len(text) <= 2000:\n",
    "            score += 0.3\n",
    "        \n",
    "        # Bonus matches dhƒÅtu\n",
    "        total_matches = sum(matches.values())\n",
    "        if total_matches > 0:\n",
    "            score += min(0.4, total_matches * 0.1)\n",
    "        \n",
    "        # Bonus diversit√© dhƒÅtu\n",
    "        if len(matches) > 1:\n",
    "            score += 0.2\n",
    "        \n",
    "        # Bonus mots-cl√©s\n",
    "        keywords = ['sanskrit', 'grammar', 'verb', 'linguistic']\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in text.lower():\n",
    "                score += 0.1\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"R√©sum√© complet des analyses\"\"\"\n",
    "        if not self.results:\n",
    "            return \"‚ùå Aucune analyse effectu√©e\"\n",
    "        \n",
    "        avg_quality = sum(r.get('quality_score', 0) for r in self.results) / len(self.results)\n",
    "        \n",
    "        return f\"\"\"üìä R√âSUM√â ANALYSE DHƒÄTU:\n",
    "‚îú‚îÄ‚îÄ Documents analys√©s: {self.stats['total_docs']}\n",
    "‚îú‚îÄ‚îÄ DhƒÅtus d√©tect√©s: {self.stats['total_matches']}\n",
    "‚îú‚îÄ‚îÄ Qualit√© moyenne: {avg_quality:.3f}/1.0\n",
    "‚îî‚îÄ‚îÄ Timestamp: {datetime.now().strftime('%H:%M:%S')}\"\"\"\n",
    "\n",
    "# Initialiser l'analyseur robuste\n",
    "analyzer = RobustDhatuAnalyzer()\n",
    "print(\"üîç Analyseur DhƒÅtu robuste initialis√©!\")\n",
    "print(f\"üéØ {len(analyzer.dhatu_patterns)} dhƒÅtus configur√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Chargement robuste des donn√©es\n",
    "def load_and_analyze_corpus():\n",
    "    \"\"\"Charge et analyse le corpus complet\"\"\"\n",
    "    data_dirs = ['data/incremental_corpus', 'colab_results']\n",
    "    total_files = 0\n",
    "    processed_docs = 0\n",
    "    \n",
    "    for data_dir in data_dirs:\n",
    "        if not os.path.exists(data_dir):\n",
    "            print(f\"‚ö†Ô∏è Dossier {data_dir} non trouv√©\")\n",
    "            continue\n",
    "            \n",
    "        files = [f for f in os.listdir(data_dir) if f.endswith('.json')]\n",
    "        total_files += len(files)\n",
    "        \n",
    "        print(f\"üìÅ {data_dir}: {len(files)} fichiers\")\n",
    "        \n",
    "        # Traiter les fichiers batch par batch\n",
    "        for i, filename in enumerate(files[:10]):  # Limite pour √©viter surcharge\n",
    "            try:\n",
    "                filepath = os.path.join(data_dir, filename)\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Analyser selon le format\n",
    "                documents = []\n",
    "                if 'documents' in data:\n",
    "                    documents = data['documents']\n",
    "                elif isinstance(data, list):\n",
    "                    documents = data\n",
    "                elif 'content' in data:\n",
    "                    documents = [data]\n",
    "                \n",
    "                # Analyser chaque document\n",
    "                for doc in documents[:5]:  # 5 docs par fichier\n",
    "                    if isinstance(doc, dict):\n",
    "                        content = doc.get('content', '') + ' ' + doc.get('title', '')\n",
    "                        source = doc.get('source', filename)\n",
    "                    else:\n",
    "                        content = str(doc)\n",
    "                        source = filename\n",
    "                    \n",
    "                    if len(content) > 50:  # Minimum de contenu\n",
    "                        result = analyzer.analyze_text(content, source)\n",
    "                        if result and result['total_matches'] > 0:\n",
    "                            processed_docs += 1\n",
    "                            title = doc.get('title', 'Sans titre') if isinstance(doc, dict) else 'Document'\n",
    "                            print(f\"‚úÖ {title[:40]}... - {result['total_matches']} dhƒÅtus (Q:{result['quality_score']:.2f})\")\n",
    "                            \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur fichier {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nüìä BILAN CHARGEMENT:\")\n",
    "    print(f\"‚îú‚îÄ‚îÄ Fichiers trouv√©s: {total_files}\")\n",
    "    print(f\"‚îú‚îÄ‚îÄ Documents trait√©s: {processed_docs}\")\n",
    "    print(f\"‚îî‚îÄ‚îÄ {analyzer.get_summary()}\")\n",
    "    \n",
    "    return processed_docs > 0\n",
    "\n",
    "# Charger et analyser\n",
    "success = load_and_analyze_corpus()\n",
    "if not success:\n",
    "    print(\"‚ö†Ô∏è Aucune donn√©e trouv√©e, analysons du contenu d'exemple...\")\n",
    "    \n",
    "    # Contenu d'exemple si pas de donn√©es\n",
    "    examples = [\n",
    "        \"Sanskrit grammar involves complex verb conjugations with dhƒÅtu roots like ‡§≠‡•Ç (to be) and ‡§ï‡•É (to do).\",\n",
    "        \"Panini's Ashtadhyayi describes how dhƒÅtus like ‡§ó‡§Æ‡•ç (to go) form various tenses and moods.\",\n",
    "        \"The verb ‡§∏‡•ç‡§•‡§æ (to stand) exemplifies the aspectual system in Sanskrit linguistics.\"\n",
    "    ]\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        analyzer.analyze_text(example, f\"example_{i+1}\")\n",
    "    \n",
    "    print(analyzer.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc91f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualisation robuste\n",
    "def create_dhatu_visualization():\n",
    "    \"\"\"Cr√©e des visualisations des r√©sultats\"\"\"\n",
    "    if not analyzer.results:\n",
    "        print(\"‚ùå Pas de donn√©es √† visualiser\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Agr√©gation des donn√©es\n",
    "        dhatu_counts = {}\n",
    "        quality_scores = []\n",
    "        \n",
    "        for result in analyzer.results:\n",
    "            for dhatu, count in result['dhatu_matches'].items():\n",
    "                dhatu_counts[dhatu] = dhatu_counts.get(dhatu, 0) + count\n",
    "            quality_scores.append(result.get('quality_score', 0))\n",
    "        \n",
    "        # Graphique 1: Distribution des dhƒÅtus\n",
    "        if dhatu_counts:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            \n",
    "            # Subplot 1: DhƒÅtus\n",
    "            plt.subplot(1, 2, 1)\n",
    "            dhatus = list(dhatu_counts.keys())\n",
    "            counts = list(dhatu_counts.values())\n",
    "            \n",
    "            bars = plt.bar(dhatus, counts, color='skyblue', alpha=0.7)\n",
    "            plt.title(f'Distribution des DhƒÅtus ({sum(counts)} total)')\n",
    "            plt.ylabel('Occurrences')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            # Ajouter valeurs sur les barres\n",
    "            for bar, count in zip(bars, counts):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                        str(count), ha='center', va='bottom')\n",
    "            \n",
    "            # Subplot 2: Qualit√©\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.hist(quality_scores, bins=10, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "            plt.title(f'Distribution Qualit√© (Œº={sum(quality_scores)/len(quality_scores):.2f})')\n",
    "            plt.xlabel('Score de qualit√©')\n",
    "            plt.ylabel('Nombre de documents')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Statistiques d√©taill√©es\n",
    "            print(\"\\nüèÜ TOP DHƒÄTUS:\")\n",
    "            sorted_dhatus = sorted(dhatu_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "            for dhatu, count in sorted_dhatus[:5]:\n",
    "                percentage = (count / sum(counts)) * 100\n",
    "                print(f\"  {dhatu}: {count} occurrences ({percentage:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nüìà QUALIT√â MOYENNE: {sum(quality_scores)/len(quality_scores):.3f}/1.0\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucun dhƒÅtu d√©tect√© pour la visualisation\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur visualisation: {e}\")\n",
    "\n",
    "# Cr√©er la visualisation\n",
    "create_dhatu_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Syst√®me de feedback robuste\n",
    "def create_and_save_feedback():\n",
    "    \"\"\"Cr√©e et sauvegarde le feedback pour le collecteur\"\"\"\n",
    "    if not analyzer.results:\n",
    "        print(\"‚ö†Ô∏è Pas assez de donn√©es pour cr√©er un feedback\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Calculer m√©triques avanc√©es\n",
    "        total_docs = len(analyzer.results)\n",
    "        total_matches = sum(r['total_matches'] for r in analyzer.results)\n",
    "        avg_quality = sum(r.get('quality_score', 0) for r in analyzer.results) / total_docs\n",
    "        \n",
    "        # Analyser les sources performantes\n",
    "        source_performance = {}\n",
    "        for result in analyzer.results:\n",
    "            source = result['source']\n",
    "            if source not in source_performance:\n",
    "                source_performance[source] = {'docs': 0, 'matches': 0, 'quality': 0}\n",
    "            \n",
    "            source_performance[source]['docs'] += 1\n",
    "            source_performance[source]['matches'] += result['total_matches']\n",
    "            source_performance[source]['quality'] += result.get('quality_score', 0)\n",
    "        \n",
    "        # Moyennes par source\n",
    "        for source in source_performance:\n",
    "            perf = source_performance[source]\n",
    "            perf['avg_matches'] = perf['matches'] / perf['docs']\n",
    "            perf['avg_quality'] = perf['quality'] / perf['docs']\n",
    "        \n",
    "        # Recommandations intelligentes\n",
    "        recommendations = {\n",
    "            'increase_batch_size': avg_quality > 0.6,\n",
    "            'focus_on_sanskrit': total_matches / total_docs > 2,\n",
    "            'diversify_sources': len(source_performance) < 3,\n",
    "            'maintain_quality': avg_quality > 0.5\n",
    "        }\n",
    "        \n",
    "        # Sources √† privil√©gier\n",
    "        best_sources = sorted(\n",
    "            [(s, p['avg_quality']) for s, p in source_performance.items()],\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )[:3]\n",
    "        \n",
    "        feedback = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'colab_analysis': {\n",
    "                'documents_processed': total_docs,\n",
    "                'dhatu_matches_found': total_matches,\n",
    "                'average_quality': round(avg_quality, 3),\n",
    "                'processing_rate': f'{total_docs}_docs_analyzed',\n",
    "                'analysis_depth': 'robust_multi_dhatu'\n",
    "            },\n",
    "            'collector_recommendations': {\n",
    "                'priority_sources': [s[0] for s in best_sources],\n",
    "                'target_quality_threshold': max(0.5, avg_quality - 0.1),\n",
    "                'suggested_batch_size': 20 if recommendations['increase_batch_size'] else 15,\n",
    "                'focus_areas': ['sanskrit_texts', 'linguistic_papers'] if recommendations['focus_on_sanskrit'] else ['general_linguistics']\n",
    "            },\n",
    "            'performance_metrics': {\n",
    "                'colab_processing_speed': 'optimal',\n",
    "                'data_consumption_rate': 'high',\n",
    "                'buffer_needs': 'continuous_feeding_required',\n",
    "                'next_analysis_ready': True\n",
    "            },\n",
    "            'source_analysis': source_performance\n",
    "        }\n",
    "        \n",
    "        # Sauvegarder le feedback\n",
    "        os.makedirs('colab_results', exist_ok=True)\n",
    "        feedback_file = 'colab_results/colab_feedback.json'\n",
    "        \n",
    "        with open(feedback_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(feedback, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"üíæ Feedback sauv√©: {feedback_file}\")\n",
    "        \n",
    "        # Tentative de synchronisation GitHub (robuste)\n",
    "        return sync_to_github_safely(feedback_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur cr√©ation feedback: {e}\")\n",
    "        return False\n",
    "\n",
    "def sync_to_github_safely(feedback_file):\n",
    "    \"\"\"Synchronisation GitHub robuste\"\"\"\n",
    "    try:\n",
    "        # V√©rifier si Git est configur√©\n",
    "        result = subprocess.run(['git', 'config', 'user.email'], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0 or not result.stdout.strip():\n",
    "            print(\"‚ÑπÔ∏è Git non configur√© - feedback sauv√© localement uniquement\")\n",
    "            print(\"üí° Pour activer GitHub, ex√©cutez:\")\n",
    "            print(\"   !git config user.email 'votre-email@example.com'\")\n",
    "            print(\"   !git config user.name 'Votre Nom'\")\n",
    "            return False\n",
    "        \n",
    "        # V√©rifier si on peut faire des commits\n",
    "        test_result = subprocess.run(['git', 'status'], capture_output=True, text=True)\n",
    "        if test_result.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è Repository Git non accessible\")\n",
    "            return False\n",
    "        \n",
    "        # Tentative de commit\n",
    "        subprocess.run(['git', 'add', feedback_file], check=True, capture_output=True)\n",
    "        \n",
    "        commit_result = subprocess.run(\n",
    "            ['git', 'commit', '-m', 'üîÑ Colab feedback: analyse dhƒÅtu robuste'],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        \n",
    "        if commit_result.returncode == 0:\n",
    "            # Tentative de push (peut √©chouer selon les credentials)\n",
    "            push_result = subprocess.run(\n",
    "                ['git', 'push', 'origin', 'main'],\n",
    "                capture_output=True, text=True, timeout=30\n",
    "            )\n",
    "            \n",
    "            if push_result.returncode == 0:\n",
    "                print(\"üöÄ Feedback synchronis√© sur GitHub!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"üíæ Feedback commit√© localement (push √©chou√©)\")\n",
    "                print(\"‚ÑπÔ∏è Synchronisation manuelle requise\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"üíæ Feedback sauv√© (rien de nouveau √† commiter)\")\n",
    "            return True\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è∞ Timeout synchronisation GitHub\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur synchronisation: {e}\")\n",
    "        print(\"üíæ Feedback reste sauv√© localement\")\n",
    "        return False\n",
    "\n",
    "# Cr√©er et sauvegarder le feedback\n",
    "feedback_success = create_and_save_feedback()\n",
    "\n",
    "if feedback_success:\n",
    "    print(\"\\n‚úÖ FEEDBACK ENVOY√â AU COLLECTEUR\")\n",
    "    print(\"ü§ñ Le collecteur va adapter sa strat√©gie\")\n",
    "else:\n",
    "    print(\"\\nüíæ Feedback sauv√© localement\")\n",
    "    print(\"üîÑ Synchronisation manuelle possible plus tard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ce769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Mode continu robuste (optionnel)\n",
    "def run_continuous_analysis_robust(duration_minutes=10, check_interval=30):\n",
    "    \"\"\"Mode d'analyse continu avec gestion d'erreurs\"\"\"\n",
    "    print(f\"üîÑ Mode continu d√©marr√©: {duration_minutes}min (v√©rification toutes les {check_interval}s)\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cycles = 0\n",
    "    last_file_count = 0\n",
    "    \n",
    "    try:\n",
    "        while (time.time() - start_time) < (duration_minutes * 60):\n",
    "            cycles += 1\n",
    "            print(f\"\\nüîç Cycle {cycles} - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            \n",
    "            # V√©rifier nouvelles donn√©es\n",
    "            try:\n",
    "                current_file_count = len([f for f in os.listdir('data/incremental_corpus') \n",
    "                                        if f.endswith('.json')])\n",
    "                \n",
    "                if current_file_count > last_file_count:\n",
    "                    new_files = current_file_count - last_file_count\n",
    "                    print(f\"üìÅ {new_files} nouveaux fichiers d√©tect√©s\")\n",
    "                    \n",
    "                    # Analyser les nouvelles donn√©es\n",
    "                    success = load_and_analyze_corpus()\n",
    "                    \n",
    "                    if success:\n",
    "                        # Cr√©er nouveau feedback\n",
    "                        create_and_save_feedback()\n",
    "                        print(f\"‚úÖ Feedback mis √† jour (cycle {cycles})\")\n",
    "                    \n",
    "                    last_file_count = current_file_count\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"üìä Pas de nouvelles donn√©es ({current_file_count} fichiers)\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur cycle {cycles}: {e}\")\n",
    "            \n",
    "            # Afficher r√©sum√©\n",
    "            print(analyzer.get_summary())\n",
    "            \n",
    "            # Attendre avant prochain cycle\n",
    "            remaining_time = (duration_minutes * 60) - (time.time() - start_time)\n",
    "            wait_time = min(check_interval, remaining_time)\n",
    "            \n",
    "            if wait_time > 0:\n",
    "                print(f\"‚è∏Ô∏è Attente {wait_time:.0f}s...\")\n",
    "                time.sleep(wait_time)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Mode continu termin√© apr√®s {cycles} cycles\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\n‚èπÔ∏è Mode continu interrompu apr√®s {cycles} cycles\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erreur mode continu: {e}\")\n",
    "\n",
    "# Interface pour lancer le mode continu\n",
    "print(\"\\nüéØ MODE CONTINU DISPONIBLE\")\n",
    "print(\"Pour activer la surveillance continue:\")\n",
    "print(\"   run_continuous_analysis_robust(duration_minutes=15)\")\n",
    "print(\"\\nüí° Le mode continu surveille les nouvelles donn√©es et met √† jour le feedback automatiquement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c991e",
   "metadata": {},
   "source": [
    "## üéØ Guide d'utilisation robuste\n",
    "\n",
    "### ‚úÖ Fonctionnalit√©s de cette version\n",
    "\n",
    "1. **Setup robuste** - Gestion automatique des credentials Git\n",
    "2. **Analyse √©tendue** - 9 dhƒÅtus + scoring de qualit√©\n",
    "3. **Visualisations** - Graphiques automatiques\n",
    "4. **Feedback intelligent** - Recommandations adapt√©es\n",
    "5. **Synchronisation s√©curis√©e** - Pas d'erreurs fatales\n",
    "6. **Mode continu** - Surveillance automatique\n",
    "\n",
    "### üöÄ Ordre d'ex√©cution recommand√©\n",
    "\n",
    "1. **Setup robuste** ‚Üê Commencez ici\n",
    "2. **Analyseur dhƒÅtu** ‚Üê Initialisation\n",
    "3. **Chargement donn√©es** ‚Üê Analyse du corpus\n",
    "4. **Visualisation** ‚Üê Graphiques des r√©sultats\n",
    "5. **Feedback** ‚Üê Communication avec collecteur\n",
    "6. **Mode continu** ‚Üê (Optionnel) Surveillance\n",
    "\n",
    "### üîß R√©solution des probl√®mes\n",
    "\n",
    "- **Git non configur√©** ‚Üí Configuration automatique\n",
    "- **Pas de donn√©es** ‚Üí Exemples fournis\n",
    "- **Erreurs push** ‚Üí Sauvegarde locale garantie\n",
    "- **Timeout** ‚Üí Gestion gracieuse\n",
    "\n",
    "üéØ **Cette version √©vite toutes les erreurs fatales !**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
