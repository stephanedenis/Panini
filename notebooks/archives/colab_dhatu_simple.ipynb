{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641b8ff7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/stephanedenis/PaniniFS-Research/blob/main/notebooks/colab_dhatu_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af085e3",
   "metadata": {},
   "source": [
    "# üöÄ DhƒÅtu Analysis - Simple & Fast\n",
    "\n",
    "Carnet Colab simple pour analyser les dhƒÅtus et interagir avec le syst√®me de collecte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Setup rapide\n",
    "import os, json, requests, time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GitHub setup\n",
    "REPO_URL = \"https://github.com/stephanedenis/PaniniFS-Research\"\n",
    "if not os.path.exists('PaniniFS-Research'):\n",
    "    !git clone $REPO_URL\n",
    "    os.chdir('PaniniFS-Research')\n",
    "else:\n",
    "    os.chdir('PaniniFS-Research')\n",
    "    !git pull origin main\n",
    "\n",
    "print(\"‚úÖ Repository ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb69d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Analyseur DhƒÅtu Simple\n",
    "class SimpleDhatuAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.dhatu_patterns = {\n",
    "            '‡§≠‡•Ç': r'‡§≠‡•Ç|bh≈´|√™tre|being',\n",
    "            '‡§ï‡•É': r'‡§ï‡•É|k·πõ|faire|doing|make',\n",
    "            '‡§ó‡§Æ‡•ç': r'‡§ó‡§Æ‡•ç|gam|aller|going|move',\n",
    "            '‡§¶‡§æ': r'‡§¶‡§æ|dƒÅ|donner|giving|give',\n",
    "            '‡§∏‡•ç‡§•‡§æ': r'‡§∏‡•ç‡§•‡§æ|sthƒÅ|√™tre debout|standing'\n",
    "        }\n",
    "        self.results = []\n",
    "    \n",
    "    def analyze_text(self, text, source=\"unknown\"):\n",
    "        \"\"\"Analyse rapide d'un texte\"\"\"\n",
    "        matches = {}\n",
    "        for dhatu, pattern in self.dhatu_patterns.items():\n",
    "            import re\n",
    "            count = len(re.findall(pattern, text, re.IGNORECASE))\n",
    "            if count > 0:\n",
    "                matches[dhatu] = count\n",
    "        \n",
    "        result = {\n",
    "            'source': source,\n",
    "            'text_length': len(text),\n",
    "            'dhatu_matches': matches,\n",
    "            'total_matches': sum(matches.values()),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        self.results.append(result)\n",
    "        return result\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"R√©sum√© des analyses\"\"\"\n",
    "        if not self.results:\n",
    "            return \"Aucune analyse effectu√©e\"\n",
    "        \n",
    "        total_docs = len(self.results)\n",
    "        total_matches = sum(r['total_matches'] for r in self.results)\n",
    "        \n",
    "        return f\"üìä {total_docs} documents analys√©s, {total_matches} dhƒÅtus d√©tect√©s\"\n",
    "\n",
    "# Initialiser l'analyseur\n",
    "analyzer = SimpleDhatuAnalyzer()\n",
    "print(\"üîç Analyseur DhƒÅtu initialis√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Charger les donn√©es collect√©es\n",
    "def load_collected_data():\n",
    "    \"\"\"Charge les donn√©es du collecteur\"\"\"\n",
    "    data_files = []\n",
    "    \n",
    "    # Chercher dans data/incremental_corpus/\n",
    "    corpus_dir = 'data/incremental_corpus'\n",
    "    if os.path.exists(corpus_dir):\n",
    "        for file in os.listdir(corpus_dir):\n",
    "            if file.endswith('.json') and 'batch_' in file:\n",
    "                data_files.append(os.path.join(corpus_dir, file))\n",
    "    \n",
    "    print(f\"üìÅ {len(data_files)} fichiers de donn√©es trouv√©s\")\n",
    "    return data_files\n",
    "\n",
    "def analyze_collected_docs():\n",
    "    \"\"\"Analyse tous les documents collect√©s\"\"\"\n",
    "    data_files = load_collected_data()\n",
    "    \n",
    "    for file_path in data_files[:5]:  # Limite √† 5 fichiers pour commencer\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if 'documents' in data:\n",
    "                for doc in data['documents'][:10]:  # 10 docs par fichier\n",
    "                    content = doc.get('content', '') + ' ' + doc.get('title', '')\n",
    "                    result = analyzer.analyze_text(content, doc.get('source', 'unknown'))\n",
    "                    print(f\"üìÑ {doc.get('title', 'Sans titre')[:50]}... - {result['total_matches']} dhƒÅtus\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur avec {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"\\n{analyzer.get_summary()}\")\n",
    "\n",
    "# Analyser les donn√©es\n",
    "analyze_collected_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Statistiques rapides\n",
    "def show_quick_stats():\n",
    "    \"\"\"Affiche des stats rapides\"\"\"\n",
    "    if not analyzer.results:\n",
    "        print(\"‚ùå Aucune donn√©e √† analyser\")\n",
    "        return\n",
    "    \n",
    "    # Cr√©er DataFrame\n",
    "    df_data = []\n",
    "    for result in analyzer.results:\n",
    "        for dhatu, count in result['dhatu_matches'].items():\n",
    "            df_data.append({\n",
    "                'dhatu': dhatu,\n",
    "                'count': count,\n",
    "                'source': result['source']\n",
    "            })\n",
    "    \n",
    "    if df_data:\n",
    "        df = pd.DataFrame(df_data)\n",
    "        \n",
    "        # Top dhƒÅtus\n",
    "        top_dhatus = df.groupby('dhatu')['count'].sum().sort_values(ascending=False)\n",
    "        print(\"üèÜ Top DhƒÅtus d√©tect√©s:\")\n",
    "        for dhatu, count in top_dhatus.head().items():\n",
    "            print(f\"  {dhatu}: {count} occurrences\")\n",
    "        \n",
    "        # Graphique simple\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top_dhatus.head().plot(kind='bar')\n",
    "        plt.title('Distribution des DhƒÅtus')\n",
    "        plt.ylabel('Occurrences')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    print(\"‚ùå Pas de donn√©es dhƒÅtu trouv√©es\")\n",
    "\n",
    "# Afficher les stats\n",
    "df_results = show_quick_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02be61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Interaction avec le collecteur\n",
    "def send_feedback_to_collector(feedback_data):\n",
    "    \"\"\"Envoie du feedback au collecteur\"\"\"\n",
    "    feedback_file = 'colab_results/colab_feedback.json'\n",
    "    \n",
    "    # Cr√©er le dossier si n√©cessaire\n",
    "    os.makedirs('colab_results', exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le feedback\n",
    "    with open(feedback_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(feedback_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Feedback sauv√© dans {feedback_file}\")\n",
    "    \n",
    "    # Tentative de commit vers GitHub (si configur√©)\n",
    "    try:\n",
    "        # V√©rifier si Git est configur√©\n",
    "        import subprocess\n",
    "        result = subprocess.run(['git', 'config', 'user.email'], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0 and result.stdout.strip():\n",
    "            # Git configur√©, on peut commiter\n",
    "            !git add colab_results/colab_feedback.json\n",
    "            !git commit -m \"üîÑ Feedback Colab: optimisations collecteur\"\n",
    "            !git push origin main\n",
    "            print(\"üöÄ Feedback envoy√© sur GitHub!\")\n",
    "        else:\n",
    "            # Git pas configur√©, juste sauvegarder localement\n",
    "            print(\"üíæ Feedback sauv√© localement (Git non configur√©)\")\n",
    "            print(\"‚ÑπÔ∏è Pour activer GitHub, configurez:\")\n",
    "            print(\"   !git config user.email 'your-email@example.com'\")\n",
    "            print(\"   !git config user.name 'Your Name'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"üíæ Feedback sauv√© localement: {e}\")\n",
    "        print(\"‚ÑπÔ∏è Synchronisation GitHub non disponible\")\n",
    "\n",
    "def create_feedback():\n",
    "    \"\"\"Cr√©e un feedback bas√© sur l'analyse\"\"\"\n",
    "    if not analyzer.results:\n",
    "        return None\n",
    "    \n",
    "    # Calculer des m√©triques\n",
    "    total_docs = len(analyzer.results)\n",
    "    total_matches = sum(r['total_matches'] for r in analyzer.results)\n",
    "    avg_matches = total_matches / total_docs if total_docs > 0 else 0\n",
    "    \n",
    "    feedback = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'analysis_summary': {\n",
    "            'documents_analyzed': total_docs,\n",
    "            'total_dhatu_matches': total_matches,\n",
    "            'average_matches_per_doc': round(avg_matches, 2)\n",
    "        },\n",
    "        'collector_recommendations': {\n",
    "            'focus_on_high_quality': avg_matches > 2,\n",
    "            'increase_sanskrit_content': True,\n",
    "            'preferred_sources': ['wikipedia_sanskrit', 'academic_papers']\n",
    "        },\n",
    "        'performance': {\n",
    "            'processing_speed': 'fast',\n",
    "            'gpu_usage': 'optimal',\n",
    "            'next_batch_ready': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return feedback\n",
    "\n",
    "# Cr√©er et envoyer feedback\n",
    "feedback = create_feedback()\n",
    "if feedback:\n",
    "    send_feedback_to_collector(feedback)\n",
    "    print(\"‚úÖ Feedback cr√©√© et envoy√©!\")\n",
    "else:\n",
    "    print(\"‚ùå Pas assez de donn√©es pour cr√©er un feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Mode continu (optionnel)\n",
    "def run_continuous_analysis(duration_minutes=10):\n",
    "    \"\"\"Mode d'analyse continu\"\"\"\n",
    "    print(f\"üîÑ D√©marrage analyse continue pour {duration_minutes} minutes...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    last_analysis = 0\n",
    "    \n",
    "    while (time.time() - start_time) < (duration_minutes * 60):\n",
    "        # V√©rifier s'il y a de nouvelles donn√©es toutes les 30 secondes\n",
    "        if time.time() - last_analysis > 30:\n",
    "            !git pull origin main --quiet\n",
    "            \n",
    "            # Analyser nouvelles donn√©es\n",
    "            data_files = load_collected_data()\n",
    "            if data_files:\n",
    "                print(f\"üìä {len(data_files)} fichiers trouv√©s, analyse en cours...\")\n",
    "                analyze_collected_docs()\n",
    "                \n",
    "                # Envoyer feedback\n",
    "                feedback = create_feedback()\n",
    "                if feedback:\n",
    "                    send_feedback_to_collector(feedback)\n",
    "            \n",
    "            last_analysis = time.time()\n",
    "        \n",
    "        time.sleep(5)  # Attendre 5 secondes\n",
    "    \n",
    "    print(\"‚úÖ Analyse continue termin√©e!\")\n",
    "\n",
    "# D√©commenter pour lancer le mode continu\n",
    "# run_continuous_analysis(5)  # 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02cb29",
   "metadata": {},
   "source": [
    "## üéØ Instructions d'utilisation\n",
    "\n",
    "1. **Ex√©cutez les cellules dans l'ordre**\n",
    "2. **Analysez les donn√©es collect√©es** avec la cellule \"data_loader\"\n",
    "3. **Visualisez les stats** avec \"quick_stats\"\n",
    "4. **Envoyez du feedback** avec \"collector_interaction\"\n",
    "5. **Mode continu optionnel** pour surveillance longue dur√©e\n",
    "\n",
    "Le carnet synchronise automatiquement avec GitHub et envoie des recommendations au collecteur local."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
