{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PaniniFS Research - Analyse Dhﾄ》u Accﾃｩlﾃｩrﾃｩe\\n",
        "\\n",
        "Analyse linguistique haute performance avec GPU/TPU\\n",
        "\\n",
        "## 泅 Configuration GPU/TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration initiale\\n",
        "!nvidia-smi\\n",
        "!pip install torch torchvision torchaudio transformers\\n",
        "!pip install pandas numpy matplotlib seaborn\\n",
        "!pip install nltk spacy scikit-learn\\n",
        "\\n",
        "import torch\\n",
        "import numpy as np\\n",
        "import pandas as pd\\n",
        "from transformers import pipeline\\n",
        "\\n",
        "# Vﾃｩrification GPU\\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n",
        "print(f'Device: {device}')\\n",
        "if torch.cuda.is_available():\\n",
        "    print(f'GPU: {torch.cuda.get_device_name()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 沒 Connexion au Workspace PaniniFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connexion au repository GitHub\\n",
        "!git clone https://github.com/stephanedenis/PaniniFS-Research.git\\n",
        "%cd PaniniFS-Research\\n",
        "\\n",
        "# Import des modules PaniniFS\\n",
        "import sys\\n",
        "sys.path.append('./src')\\n",
        "\\n",
        "from analysis.analyseur_molecules_semantiques import MoleculeAnalyzer\\n",
        "from dhatu.aspect_dhatu import AspectAnalyzer\\n",
        "from corpus.universal_atoms_extractor import AtomExtractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 洫 Analyse Dhﾄ》u avec Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ColabDhatuAnalyzer:\\n",
        "    def __init__(self, device='cuda'):\\n",
        "        self.device = device\\n",
        "        self.sentiment_pipeline = pipeline('sentiment-analysis', device=0 if device=='cuda' else -1)\\n",
        "        self.ner_pipeline = pipeline('ner', device=0 if device=='cuda' else -1)\\n",
        "        \\n",
        "    def analyze_semantic_patterns(self, texts: list):\\n",
        "        \\\"\\\"\\\"Analyse sﾃｩmantique accﾃｩlﾃｩrﾃｩe par GPU\\\"\\\"\\\"\\n",
        "        results = []\\n",
        "        \\n",
        "        for text in texts:\\n",
        "            # Analyse de sentiment\\n",
        "            sentiment = self.sentiment_pipeline(text)\\n",
        "            \\n",
        "            # Reconnaissance d'entitﾃｩs\\n",
        "            entities = self.ner_pipeline(text)\\n",
        "            \\n",
        "            # Extraction de patterns dhﾄ》u\\n",
        "            dhatu_patterns = self.extract_dhatu_patterns(text)\\n",
        "            \\n",
        "            results.append({\\n",
        "                'text': text,\\n",
        "                'sentiment': sentiment,\\n",
        "                'entities': entities,\\n",
        "                'dhatu_patterns': dhatu_patterns\\n",
        "            })\\n",
        "            \\n",
        "        return results\\n",
        "        \\n",
        "    def extract_dhatu_patterns(self, text):\\n",
        "        \\\"\\\"\\\"Extraction de patterns dhﾄ》u spﾃｩcifiques\\\"\\\"\\\"\\n",
        "        # Patterns aspectuels\\n",
        "        aspectual_markers = ['was', 'were', 'will', 'would', 'has', 'have', 'had']\\n",
        "        modal_markers = ['can', 'could', 'may', 'might', 'should', 'must']\\n",
        "        \\n",
        "        patterns = {\\n",
        "            'aspectual': [marker for marker in aspectual_markers if marker in text.lower()],\\n",
        "            'modal': [marker for marker in modal_markers if marker in text.lower()]\\n",
        "        }\\n",
        "        \\n",
        "        return patterns\\n",
        "\\n",
        "# Initialisation\\n",
        "analyzer = ColabDhatuAnalyzer(device=str(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 沒 Traitement Batch de Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement de corpus depuis PaniniFS\\n",
        "import json\\n",
        "\\n",
        "def load_corpus_data():\\n",
        "    corpus_files = []\\n",
        "    data_dir = Path('./data')\\n",
        "    \\n",
        "    if data_dir.exists():\\n",
        "        corpus_files = list(data_dir.glob('corpus*.json'))\\n",
        "        \\n",
        "    print(f'Corpus trouvﾃｩs: {len(corpus_files)}')\\n",
        "    return corpus_files\\n",
        "\\n",
        "def process_corpus_batch(corpus_files, batch_size=32):\\n",
        "    \\\"\\\"\\\"Traitement par batch pour optimiser GPU\\\"\\\"\\\"\\n",
        "    all_results = []\\n",
        "    \\n",
        "    for corpus_file in corpus_files:\\n",
        "        print(f'Traitement: {corpus_file.name}')\\n",
        "        \\n",
        "        with open(corpus_file, 'r', encoding='utf-8') as f:\\n",
        "            data = json.load(f)\\n",
        "            \\n",
        "        # Extraction des textes\\n",
        "        texts = []\\n",
        "        if isinstance(data, dict):\\n",
        "            texts = [str(v) for v in data.values() if isinstance(v, str)]\\n",
        "        elif isinstance(data, list):\\n",
        "            texts = [str(item) for item in data if isinstance(item, str)]\\n",
        "            \\n",
        "        # Traitement par batch\\n",
        "        for i in range(0, len(texts), batch_size):\\n",
        "            batch = texts[i:i+batch_size]\\n",
        "            batch_results = analyzer.analyze_semantic_patterns(batch)\\n",
        "            all_results.extend(batch_results)\\n",
        "            \\n",
        "            print(f'  Batch {i//batch_size + 1}: {len(batch)} textes traitﾃｩs')\\n",
        "            \\n",
        "    return all_results\\n",
        "\\n",
        "# Exﾃｩcution\\n",
        "corpus_files = load_corpus_data()\\n",
        "if corpus_files:\\n",
        "    results = process_corpus_batch(corpus_files)\\n",
        "    print(f'\\\\n笨 Analyse terminﾃｩe: {len(results)} ﾃｩlﾃｩments traitﾃｩs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 沒 Visualisation des Rﾃｩsultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\\n",
        "import seaborn as sns\\n",
        "from collections import Counter\\n",
        "\\n",
        "def visualize_dhatu_analysis(results):\\n",
        "    \\\"\\\"\\\"Visualise les rﾃｩsultats d'analyse dhﾄ》u\\\"\\\"\\\"\\n",
        "    \\n",
        "    # Analyse des sentiments\\n",
        "    sentiments = [r['sentiment'][0]['label'] for r in results if r['sentiment']]\\n",
        "    sentiment_counts = Counter(sentiments)\\n",
        "    \\n",
        "    # Patterns dhﾄ》u\\n",
        "    aspectual_patterns = []\\n",
        "    modal_patterns = []\\n",
        "    \\n",
        "    for r in results:\\n",
        "        aspectual_patterns.extend(r['dhatu_patterns']['aspectual'])\\n",
        "        modal_patterns.extend(r['dhatu_patterns']['modal'])\\n",
        "        \\n",
        "    aspectual_counts = Counter(aspectual_patterns)\\n",
        "    modal_counts = Counter(modal_patterns)\\n",
        "    \\n",
        "    # Visualisations\\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n",
        "    \\n",
        "    # Sentiments\\n",
        "    axes[0, 0].pie(sentiment_counts.values(), labels=sentiment_counts.keys(), autopct='%1.1f%%')\\n",
        "    axes[0, 0].set_title('Distribution des Sentiments')\\n",
        "    \\n",
        "    # Patterns aspectuels\\n",
        "    if aspectual_counts:\\n",
        "        axes[0, 1].bar(aspectual_counts.keys(), aspectual_counts.values())\\n",
        "        axes[0, 1].set_title('Marqueurs Aspectuels')\\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\\n",
        "    \\n",
        "    # Patterns modaux\\n",
        "    if modal_counts:\\n",
        "        axes[1, 0].bar(modal_counts.keys(), modal_counts.values())\\n",
        "        axes[1, 0].set_title('Marqueurs Modaux')\\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\\n",
        "    \\n",
        "    # Entitﾃｩs\\n",
        "    entity_types = []\\n",
        "    for r in results:\\n",
        "        for entity in r['entities']:\\n",
        "            entity_types.append(entity['entity'])\\n",
        "    \\n",
        "    if entity_types:\\n",
        "        entity_counts = Counter(entity_types)\\n",
        "        top_entities = dict(entity_counts.most_common(10))\\n",
        "        axes[1, 1].bar(top_entities.keys(), top_entities.values())\\n",
        "        axes[1, 1].set_title('Top 10 Types d\\'Entitﾃｩs')\\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\\n",
        "    \\n",
        "    plt.tight_layout()\\n",
        "    plt.show()\\n",
        "    \\n",
        "    # Statistiques\\n",
        "    print('\\\\n沒 STATISTIQUES DHﾄTU:')\\n",
        "    print(f'Total textes analysﾃｩs: {len(results)}')\\n",
        "    print(f'Patterns aspectuels uniques: {len(aspectual_counts)}')\\n",
        "    print(f'Patterns modaux uniques: {len(modal_counts)}')\\n",
        "    print(f'Types d\\'entitﾃｩs: {len(Counter(entity_types))}')\\n",
        "\\n",
        "# Visualisation\\n",
        "if 'results' in locals() and results:\\n",
        "    visualize_dhatu_analysis(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 汳ｾ Export des Rﾃｩsultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export vers Google Drive\\n",
        "from google.colab import drive\\n",
        "drive.mount('/content/drive')\\n",
        "\\n",
        "# Sauvegarde\\n",
        "import datetime\\n",
        "\\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\\n",
        "export_file = f'/content/drive/MyDrive/panini_dhatu_analysis_{timestamp}.json'\\n",
        "\\n",
        "if 'results' in locals():\\n",
        "    with open(export_file, 'w', encoding='utf-8') as f:\\n",
        "        json.dump(results, f, indent=2, ensure_ascii=False)\\n",
        "    \\n",
        "    print(f'笨 Rﾃｩsultats exportﾃｩs: {export_file}')\\n",
        "    print(f'沒 {len(results)} analyses sauvegardﾃｩes')\\n",
        "\\n",
        "# Crﾃｩation d'un rapport\\n",
        "report = {\\n",
        "    'timestamp': timestamp,\\n",
        "    'device': str(device),\\n",
        "    'total_analyses': len(results) if 'results' in locals() else 0,\\n",
        "    'gpu_info': torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU',\\n",
        "    'corpus_files_processed': len(corpus_files) if 'corpus_files' in locals() else 0\\n",
        "}\\n",
        "\\n",
        "report_file = f'/content/drive/MyDrive/panini_report_{timestamp}.json'\\n",
        "with open(report_file, 'w', encoding='utf-8') as f:\\n",
        "    json.dump(report, f, indent=2)\\n",
        "\\n",
        "print(f'沒 Rapport sauvegardﾃｩ: {report_file}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}