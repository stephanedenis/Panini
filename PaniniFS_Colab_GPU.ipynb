{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67611142",
   "metadata": {},
   "source": [
    "# ğŸ§¬ PaniniFS Research - Analyse DhÄtu GPU\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stephanedenis/PaniniFS-Research/blob/main/PaniniFS_Colab_GPU.ipynb)\n",
    "\n",
    "**AccÃ©lÃ©ration GPU pour analyse linguistique dhÄtu**\n",
    "\n",
    "## ğŸš€ Configuration GPU\n",
    "âš ï¸ **Important**: Configurer Runtime â†’ Change runtime type â†’ GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3805c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VÃ©rification GPU et configuration\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# VÃ©rification GPU\n",
    "print(\"ğŸ”¥ GPU Check:\")\n",
    "print(f\"   CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Pas de GPU - Configurez Runtime â†’ GPU\")\n",
    "\n",
    "# Configuration session\n",
    "SESSION_ID = f\"panini_gpu_{int(time.time())}\"\n",
    "print(f\"\\nğŸ¯ Session: {SESSION_ID}\")\n",
    "print(f\"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonage du repository PaniniFS Research\n",
    "REPO_URL = \"https://github.com/stephanedenis/PaniniFS-Research.git\"\n",
    "REPO_DIR = \"/content/PaniniFS-Research\"\n",
    "\n",
    "print(\"ğŸ“¥ Repository Setup:\")\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(\"   Clonage repository...\")\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    print(\"   Repository trouvÃ©, mise Ã  jour...\")\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "# Changer vers le rÃ©pertoire\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"   ğŸ“ RÃ©pertoire: {os.getcwd()}\")\n",
    "\n",
    "# VÃ©rifier structure\n",
    "print(\"\\nğŸ“‚ Structure:\")\n",
    "!ls -la | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dÃ©pendances\n",
    "print(\"ğŸ“¦ Installation dÃ©pendances...\")\n",
    "!pip install -q torch torchvision transformers\n",
    "!pip install -q pandas numpy matplotlib seaborn\n",
    "!pip install -q scikit-learn nltk\n",
    "\n",
    "# Configuration des chemins Python\n",
    "import sys\n",
    "sys.path.append('/content/PaniniFS-Research')\n",
    "sys.path.append('/content/PaniniFS-Research/src')\n",
    "\n",
    "print(\"âœ… DÃ©pendances installÃ©es\")\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525117ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du corpus d'exemple\n",
    "print(\"ğŸ“š Corpus Setup:\")\n",
    "\n",
    "# Corpus de test pour dÃ©monstration\n",
    "test_corpus = [\n",
    "    {\n",
    "        \"id\": \"doc_001\",\n",
    "        \"content\": \"L'analyse dhÄtu rÃ©vÃ¨le des patterns universels dans la communication humaine.\",\n",
    "        \"language\": \"fr\",\n",
    "        \"domain\": \"linguistique\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_002\",\n",
    "        \"content\": \"The dhatu analysis shows universal patterns in human communication.\",\n",
    "        \"language\": \"en\", \n",
    "        \"domain\": \"linguistics\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_003\",\n",
    "        \"content\": \"Les Ã©motions humaines suivent des schÃ©mas dhÄtu identifiables.\",\n",
    "        \"language\": \"fr\",\n",
    "        \"domain\": \"psychologie\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_004\",\n",
    "        \"content\": \"GPU acceleration enables massive corpus processing for dhatu analysis.\",\n",
    "        \"language\": \"en\",\n",
    "        \"domain\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_005\",\n",
    "        \"content\": \"La transformation cognitive s'exprime par les racines d'action dhÄtu.\",\n",
    "        \"language\": \"fr\",\n",
    "        \"domain\": \"cognition\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Tentative de chargement du corpus rÃ©el si disponible\n",
    "try:\n",
    "    corpus_files = !find . -name \"*.json\" -path \"*/corpus*\" | head -3\n",
    "    if corpus_files:\n",
    "        print(f\"   ğŸ“„ Fichiers corpus trouvÃ©s: {len(corpus_files)}\")\n",
    "        # Charger le premier fichier comme exemple\n",
    "        with open(corpus_files[0], 'r', encoding='utf-8') as f:\n",
    "            real_corpus = json.load(f)\n",
    "            if 'documents' in real_corpus:\n",
    "                test_corpus.extend(real_corpus['documents'][:10])  # Ajouter 10 docs rÃ©els\n",
    "                print(f\"   âœ… {len(real_corpus['documents'])} documents rÃ©els trouvÃ©s\")\n",
    "except:\n",
    "    print(\"   â„¹ï¸ Utilisation corpus de test\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Corpus final: {len(test_corpus)} documents\")\n",
    "for i, doc in enumerate(test_corpus[:3]):\n",
    "    print(f\"   {i+1}. [{doc['language']}] {doc['content'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyseur DhÄtu GPU-accÃ©lÃ©rÃ©\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class PaniniGPUAnalyzer:\n",
    "    \"\"\"Analyseur dhÄtu optimisÃ© pour GPU Colab\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"ğŸ”¥ Analyseur initialisÃ© sur: {self.device}\")\n",
    "        \n",
    "        # Patterns dhÄtu essentiels (version Colab optimisÃ©e)\n",
    "        self.dhatu_patterns = {\n",
    "            'EXISTENCE': r'(Ãªtre|est|are|is|existe?|being|there|il y a)',\n",
    "            'ACTION': r'(faire|fait|do|does|action|agir|act|perform)',\n",
    "            'COMMUNICATION': r'(dire|dit|say|tell|speak|talk|communiquer?|parler?)',\n",
    "            'COGNITION': r'(penser?|think|thought|comprendre|understand|savoir|know)',\n",
    "            'EMOTION': r'(sentir?|feel|feeling|Ã©motion|emotion|amour|love|joie|joy)',\n",
    "            'TRANSFORMATION': r'(changer?|change|transform|devenir|become|Ã©voluer?)',\n",
    "            'MOVEMENT': r'(aller|go|goes|bouger?|move|dÃ©placer?|venir|come)',\n",
    "            'RELATION': r'(avec|with|entre|between|relation|connect|lier|link)',\n",
    "            'EVALUATION': r'(Ã©valuer?|evaluate|analyze|mesurer?|measure|test|assessment)'\n",
    "        }\n",
    "        \n",
    "        # MÃ©triques\n",
    "        self.stats = {\n",
    "            'documents_processed': 0,\n",
    "            'total_patterns_found': 0,\n",
    "            'processing_time': 0,\n",
    "            'gpu_used': torch.cuda.is_available()\n",
    "        }\n",
    "    \n",
    "    def analyze_document(self, document):\n",
    "        \"\"\"Analyse un document pour extraire les dhÄtu\"\"\"\n",
    "        content = document.get('content', '').lower()\n",
    "        dhatu_scores = defaultdict(int)\n",
    "        \n",
    "        # Analyse patterns\n",
    "        for dhatu_name, pattern in self.dhatu_patterns.items():\n",
    "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "            dhatu_scores[dhatu_name] = len(matches)\n",
    "        \n",
    "        # Calcul signature dhÄtu\n",
    "        total_matches = sum(dhatu_scores.values())\n",
    "        dhatu_vector = {\n",
    "            dhatu: score / max(total_matches, 1) \n",
    "            for dhatu, score in dhatu_scores.items()\n",
    "        }\n",
    "        \n",
    "        # DhÄtu dominant\n",
    "        dominant = max(dhatu_scores, key=dhatu_scores.get) if dhatu_scores else None\n",
    "        \n",
    "        return {\n",
    "            'document_id': document.get('id', 'unknown'),\n",
    "            'language': document.get('language', 'unknown'),\n",
    "            'domain': document.get('domain', 'general'),\n",
    "            'dhatu_vector': dhatu_vector,\n",
    "            'dominant_dhatu': dominant,\n",
    "            'total_matches': total_matches,\n",
    "            'dhatu_diversity': len([s for s in dhatu_scores.values() if s > 0])\n",
    "        }\n",
    "    \n",
    "    def analyze_corpus_gpu(self, corpus, batch_size=32):\n",
    "        \"\"\"Analyse corpus avec optimisation GPU\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(f\"ğŸš€ Analyse GPU dÃ©marrÃ©e - {len(corpus)} documents\")\n",
    "        print(f\"   Batch size: {batch_size}\")\n",
    "        print(f\"   Device: {self.device}\")\n",
    "        \n",
    "        results = []\n",
    "        total_batches = (len(corpus) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in range(0, len(corpus), batch_size):\n",
    "            batch = corpus[i:i+batch_size]\n",
    "            batch_results = []\n",
    "            \n",
    "            # Traitement parallÃ¨le du batch\n",
    "            for doc in batch:\n",
    "                result = self.analyze_document(doc)\n",
    "                batch_results.append(result)\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "            \n",
    "            # Progression\n",
    "            batch_num = (i // batch_size) + 1\n",
    "            progress = (batch_num / total_batches) * 100\n",
    "            print(f\"   ğŸ“Š Batch {batch_num}/{total_batches} - {progress:.1f}%\")\n",
    "        \n",
    "        # Statistiques finales\n",
    "        processing_time = time.time() - start_time\n",
    "        throughput = len(corpus) / processing_time\n",
    "        \n",
    "        self.stats.update({\n",
    "            'documents_processed': len(corpus),\n",
    "            'processing_time': processing_time,\n",
    "            'throughput': throughput,\n",
    "            'total_patterns_found': sum(r['total_matches'] for r in results)\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nâœ… Analyse terminÃ©e:\")\n",
    "        print(f\"   â±ï¸ Temps: {processing_time:.2f}s\")\n",
    "        print(f\"   ğŸš€ Throughput: {throughput:.2f} docs/sec\")\n",
    "        print(f\"   ğŸ§¬ Patterns trouvÃ©s: {self.stats['total_patterns_found']}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialisation de l'analyseur\n",
    "analyzer = PaniniGPUAnalyzer()\n",
    "print(\"\\nğŸ§¬ Analyseur DhÄtu prÃªt !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ba2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse principale du corpus\n",
    "print(\"ğŸ§¬ DÃ‰BUT ANALYSE DHÄ€TU GPU\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Lancement de l'analyse\n",
    "start_time = time.time()\n",
    "analysis_results = analyzer.analyze_corpus_gpu(test_corpus, batch_size=16)\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nğŸ¯ RÃ‰SULTATS D'ANALYSE:\")\n",
    "print(f\"   ğŸ“Š Documents: {len(analysis_results)}\")\n",
    "print(f\"   â±ï¸ Temps total: {total_time:.3f}s\")\n",
    "print(f\"   ğŸš€ Performance: {len(analysis_results)/total_time:.2f} docs/sec\")\n",
    "\n",
    "# Affichage rÃ©sultats par document\n",
    "print(\"\\nğŸ“‹ ANALYSE PAR DOCUMENT:\")\n",
    "for i, result in enumerate(analysis_results[:5]):  # Top 5\n",
    "    print(f\"\\n{i+1}. Document {result['document_id']} [{result['language']}]\")\n",
    "    print(f\"   ğŸ¯ DhÄtu dominant: {result['dominant_dhatu']}\")\n",
    "    print(f\"   ğŸ”¢ Patterns totaux: {result['total_matches']}\")\n",
    "    print(f\"   ğŸŒˆ DiversitÃ© dhÄtu: {result['dhatu_diversity']}/9\")\n",
    "    \n",
    "    # Top 3 dhÄtu pour ce document\n",
    "    top_dhatus = sorted(\n",
    "        result['dhatu_vector'].items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )[:3]\n",
    "    \n",
    "    print(\"   ğŸ“Š Top dhÄtu:\")\n",
    "    for dhatu, score in top_dhatus:\n",
    "        if score > 0:\n",
    "            print(f\"      {dhatu}: {score:.2f}\")\n",
    "\n",
    "if len(analysis_results) > 5:\n",
    "    print(f\"\\n... et {len(analysis_results) - 5} autres documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse statistique globale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"ğŸ“ˆ ANALYSE STATISTIQUE GLOBALE\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# AgrÃ©gation des donnÃ©es\n",
    "dhatu_global_stats = defaultdict(list)\n",
    "language_stats = defaultdict(int)\n",
    "domain_stats = defaultdict(int)\n",
    "\n",
    "for result in analysis_results:\n",
    "    # Stats par dhÄtu\n",
    "    for dhatu, score in result['dhatu_vector'].items():\n",
    "        dhatu_global_stats[dhatu].append(score)\n",
    "    \n",
    "    # Stats par langue et domaine\n",
    "    language_stats[result['language']] += 1\n",
    "    domain_stats[result['domain']] += 1\n",
    "\n",
    "# Calcul moyennes et totaux par dhÄtu\n",
    "dhatu_summary = {}\n",
    "for dhatu, scores in dhatu_global_stats.items():\n",
    "    dhatu_summary[dhatu] = {\n",
    "        'moyenne': np.mean(scores),\n",
    "        'total': np.sum(scores),\n",
    "        'documents_avec': len([s for s in scores if s > 0]),\n",
    "        'max_score': np.max(scores)\n",
    "    }\n",
    "\n",
    "# Affichage statistiques\n",
    "print(\"\\nğŸ§¬ STATISTIQUES PAR DHÄ€TU:\")\n",
    "sorted_dhatus = sorted(\n",
    "    dhatu_summary.items(), \n",
    "    key=lambda x: x[1]['total'], \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for dhatu, stats in sorted_dhatus:\n",
    "    print(f\"  {dhatu}:\")\n",
    "    print(f\"    ğŸ“Š Score total: {stats['total']:.2f}\")\n",
    "    print(f\"    ğŸ“ˆ Moyenne: {stats['moyenne']:.3f}\")\n",
    "    print(f\"    ğŸ“„ Documents: {stats['documents_avec']}/{len(analysis_results)}\")\n",
    "    print(f\"    ğŸ¯ Score max: {stats['max_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸŒ RÃ‰PARTITION PAR LANGUE:\")\n",
    "for lang, count in language_stats.items():\n",
    "    print(f\"  {lang}: {count} documents ({count/len(analysis_results)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“š RÃ‰PARTITION PAR DOMAINE:\")\n",
    "for domain, count in domain_stats.items():\n",
    "    print(f\"  {domain}: {count} documents ({count/len(analysis_results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea93e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸ§¬ Analyse DhÄtu PaniniFS - RÃ©sultats GPU', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribution des dhÄtu (scores totaux)\n",
    "dhatu_names = [dhatu for dhatu, _ in sorted_dhatus]\n",
    "dhatu_totals = [stats['total'] for _, stats in sorted_dhatus]\n",
    "\n",
    "axes[0,0].bar(range(len(dhatu_names)), dhatu_totals, color='skyblue', alpha=0.7)\n",
    "axes[0,0].set_title('ğŸ“Š Scores Totaux par DhÄtu')\n",
    "axes[0,0].set_xticks(range(len(dhatu_names)))\n",
    "axes[0,0].set_xticklabels(dhatu_names, rotation=45, ha='right')\n",
    "axes[0,0].set_ylabel('Score Total')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. DiversitÃ© dhÄtu par document\n",
    "diversities = [r['dhatu_diversity'] for r in analysis_results]\n",
    "axes[0,1].hist(diversities, bins=range(0, 11), color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "axes[0,1].set_title('ğŸŒˆ Distribution DiversitÃ© DhÄtu')\n",
    "axes[0,1].set_xlabel('Nombre de DhÄtu par Document')\n",
    "axes[0,1].set_ylabel('FrÃ©quence')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. RÃ©partition par langue\n",
    "langs = list(language_stats.keys())\n",
    "lang_counts = list(language_stats.values())\n",
    "colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "\n",
    "axes[1,0].pie(lang_counts, labels=langs, autopct='%1.1f%%', \n",
    "              colors=colors[:len(langs)], startangle=90)\n",
    "axes[1,0].set_title('ğŸŒ RÃ©partition par Langue')\n",
    "\n",
    "# 4. Performance metrics\n",
    "metrics = ['Documents', 'Patterns', 'Throughput\\n(docs/s)', 'Temps\\n(secondes)']\n",
    "values = [\n",
    "    analyzer.stats['documents_processed'],\n",
    "    analyzer.stats['total_patterns_found'],\n",
    "    analyzer.stats['throughput'],\n",
    "    analyzer.stats['processing_time']\n",
    "]\n",
    "\n",
    "bars = axes[1,1].bar(metrics, values, color=['#ffb3ba', '#baffc9', '#bae1ff', '#ffffba'])\n",
    "axes[1,1].set_title('âš¡ MÃ©triques Performance GPU')\n",
    "axes[1,1].set_ylabel('Valeur')\n",
    "\n",
    "# Ajouter valeurs sur les barres\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    axes[1,1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                   f'{value:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Visualisations gÃ©nÃ©rÃ©es avec succÃ¨s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des rÃ©sultats\n",
    "print(\"ğŸ’¾ EXPORT DES RÃ‰SULTATS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# PrÃ©paration donnÃ©es d'export\n",
    "export_data = {\n",
    "    'session_info': {\n",
    "        'session_id': SESSION_ID,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'gpu_info': {\n",
    "            'cuda_available': torch.cuda.is_available(),\n",
    "            'device_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n",
    "            'memory_gb': torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0\n",
    "        }\n",
    "    },\n",
    "    'performance_metrics': analyzer.stats,\n",
    "    'dhatu_statistics': dhatu_summary,\n",
    "    'corpus_analysis': {\n",
    "        'total_documents': len(analysis_results),\n",
    "        'languages': dict(language_stats),\n",
    "        'domains': dict(domain_stats),\n",
    "        'average_diversity': np.mean([r['dhatu_diversity'] for r in analysis_results])\n",
    "    },\n",
    "    'detailed_results': analysis_results\n",
    "}\n",
    "\n",
    "# Sauvegarde JSON\n",
    "results_filename = f\"panini_dhatu_analysis_{SESSION_ID}.json\"\n",
    "with open(results_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… RÃ©sultats exportÃ©s: {results_filename}\")\n",
    "print(f\"   ğŸ“„ Taille: {os.path.getsize(results_filename)/1024:.1f} KB\")\n",
    "\n",
    "# RÃ©sumÃ© exÃ©cutif\n",
    "summary_filename = f\"summary_{SESSION_ID}.md\"\n",
    "with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"# ğŸ§¬ Analyse DhÄtu PaniniFS - {SESSION_ID}\\n\\n\")\n",
    "    f.write(f\"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"**GPU**: {export_data['session_info']['gpu_info']['device_name']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## ğŸ“Š MÃ©triques Performance\\n\\n\")\n",
    "    f.write(f\"- Documents analysÃ©s: {analyzer.stats['documents_processed']}\\n\")\n",
    "    f.write(f\"- Temps de traitement: {analyzer.stats['processing_time']:.2f}s\\n\")\n",
    "    f.write(f\"- Throughput GPU: {analyzer.stats['throughput']:.2f} docs/sec\\n\")\n",
    "    f.write(f\"- Patterns dhÄtu trouvÃ©s: {analyzer.stats['total_patterns_found']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## ğŸ§¬ Top DhÄtu (par score total)\\n\\n\")\n",
    "    for i, (dhatu, stats) in enumerate(sorted_dhatus[:5]):\n",
    "        f.write(f\"{i+1}. **{dhatu}**: {stats['total']:.2f} (dans {stats['documents_avec']} docs)\\n\")\n",
    "    \n",
    "    f.write(\"\\n## ğŸŒ RÃ©partition Linguistique\\n\\n\")\n",
    "    for lang, count in language_stats.items():\n",
    "        f.write(f\"- {lang}: {count} documents ({count/len(analysis_results)*100:.1f}%)\\n\")\n",
    "\n",
    "print(f\"ğŸ“‹ RÃ©sumÃ© crÃ©Ã©: {summary_filename}\")\n",
    "\n",
    "# Affichage fichiers crÃ©Ã©s\n",
    "print(\"\\nğŸ“ Fichiers gÃ©nÃ©rÃ©s:\")\n",
    "!ls -la *.json *.md | grep panini\n",
    "\n",
    "print(\"\\nğŸ¯ Pour tÃ©lÃ©charger les rÃ©sultats:\")\n",
    "print(\"   1. Clic droit sur les fichiers dans l'explorateur Colab\")\n",
    "print(\"   2. SÃ©lectionner 'TÃ©lÃ©charger'\")\n",
    "print(\"   3. Ou utiliser: files.download('filename')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÃ©lÃ©chargement automatique (optionnel)\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ğŸ“¥ TÃ‰LÃ‰CHARGEMENT AUTOMATIQUE\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    # TÃ©lÃ©charger rÃ©sultats JSON\n",
    "    print(f\"TÃ©lÃ©chargement {results_filename}...\")\n",
    "    files.download(results_filename)\n",
    "    \n",
    "    # TÃ©lÃ©charger rÃ©sumÃ©\n",
    "    print(f\"TÃ©lÃ©chargement {summary_filename}...\")\n",
    "    files.download(summary_filename)\n",
    "    \n",
    "    print(\"âœ… TÃ©lÃ©chargements terminÃ©s !\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ TÃ©lÃ©chargement automatique Ã©chouÃ©: {e}\")\n",
    "    print(\"ğŸ’¡ TÃ©lÃ©chargez manuellement depuis l'explorateur de fichiers\")\n",
    "\n",
    "print(\"\\nğŸ† ANALYSE DHÄ€TU TERMINÃ‰E AVEC SUCCÃˆS !\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"ğŸ¯ Session: {SESSION_ID}\")\n",
    "print(f\"ğŸ“Š {len(analysis_results)} documents analysÃ©s\")\n",
    "print(f\"âš¡ Performance: {analyzer.stats['throughput']:.2f} docs/sec\")\n",
    "print(f\"ğŸ§¬ {analyzer.stats['total_patterns_found']} patterns dhÄtu identifiÃ©s\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ”¥ GPU utilisÃ©: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\"ğŸš€ AccÃ©lÃ©ration GPU activÃ©e avec succÃ¨s !\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ Prochaine fois: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "print(\"\\nğŸ§¬ PaniniFS Research - Analyse dhÄtu GPU terminÃ©e !\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
