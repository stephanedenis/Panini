# Guide Technique - Tokenisation Contextuelle Compl√®te v7.1

## Philosophie et Principes

### Principe Fondamental
**RIEN ne doit √™tre perdu, m√™me ce qu'on ne comprend pas encore.**

La tokenisation traditionnelle ignore souvent les √©l√©ments "non significatifs" comme la ponctuation, les espaces, ou les choix de casse. Notre approche consid√®re que chaque √©l√©ment porte potentiellement du sens s√©mantique crucial qui pourrait √™tre compris plus tard.

### Vision Humaine
Au quotidien, les humains op√®rent sans comprendre tous les d√©terminants du locuteur, mais certains pourraient faire une th√®se de doctorat sur chaque phrase d'un locuteur particulier. D'o√π l'importance de ne pas ignorer ces √©l√©ments, mais de les √©tiqueter pour investigation future.

## Architecture Technique

### Structure des Donn√©es

```python
@dataclass
class ElementLinguistique:
    """√âl√©ment linguistique avec contexte complet"""
    
    # Identification unique
    id: str                          # UUID unique pour tra√ßabilit√©
    contenu: str                     # Le texte exact, inchang√©
    
    # Position et structure
    type_element: str                # Classification pr√©cise
    position_absolue: int            # Position caract√®re dans l'original
    position_relative: int           # Position dans la s√©quence d'√©l√©ments
    
    # Contexte spatial
    contexte_gauche: str             # 3 √©l√©ments pr√©c√©dents
    contexte_droit: str              # 3 √©l√©ments suivants
    
    # Analyse linguistique
    langue_detectee: str             # Langue identifi√©e
    probable_fonction_grammaticale: str  # Fonction grammaticale suppos√©e
    niveau_certitude: float          # Confiance dans l'analyse (0.0-1.0)
    
    # √âtiquetage des incertitudes
    etiquettes_temporaires: List[str]     # Marqueurs pour r√©vision
    variables_inconnues: Dict[str, Any]   # √âl√©ments √† √©lucider
    
    # M√©tadonn√©es de tra√ßabilit√©
    locuteur: str                    # Qui a produit ce texte
    contexte_situationnel: str       # Dans quel contexte
    moment_traitement: str           # Timestamp ISO pr√©cis
    version_pipeline: str            # Version du syst√®me
    etat_modele: str                 # √âtat du mod√®le au moment T
    
    # Support pour textes traduits
    traducteur_original: str = None   # Qui a traduit (si applicable)
    contexte_traduction: str = None   # Contexte de traduction
    moment_traduction: str = None     # Quand traduit
```

### Types d'√âl√©ments Identifi√©s

| Type | Description | Exemples | Enjeux S√©mantiques |
|------|-------------|----------|-------------------|
| `mot_majuscule` | Mot commen√ßant par majuscule | `Il`, `Paris`, `Dr` | D√©but de phrase vs nom propre |
| `mot_minuscule` | Mot en minuscules | `√©tait`, `chat`, `avec` | Contenu lexical principal |
| `espace` | Espace simple ou multiple | ` `, `  ` | S√©paration, pause, emphasis |
| `ponctuation` | Signes de ponctuation | `.`, `,`, `!`, `?` | Intention, rythme, structure |
| `apostrophe` | Apostrophes et contractions | `'`, `'` | Registre, forme contract√©e |
| `chiffre` | Nombres et chiffres | `123`, `1er` | Quantit√©, ordre, r√©f√©rence |
| `element_special` | Caract√®res non cat√©goris√©s | `‚Äî`, `¬´¬ª, `‚Ä¶` | Signification inconnue |

## √âtiquetage Temporaire des Incertitudes

### Cat√©gories d'√âtiquettes

#### Niveau de Certitude
- `INCERTAIN` : Analyse douteuse (certitude < 0.7)
- `SEMANTIQUE_A_DETERMINER` : Sens √† √©lucider
- `FONCTION_GRAMMATICALE_FLOUE` : R√¥le syntaxique incertain

#### √âl√©ments Sp√©ciaux
- `ELEMENT_SPECIAL_NON_CATEGORISE` : Type inconnu
- `CARACTERE_ISOLE_SIGNIFICATION_INCONNUE` : Caract√®re unique inexpliqu√©
- `CHOIX_CASSE_INEXPLIQUE` : Majuscule/minuscule sans justification

#### Variables Inconnues Document√©es

```python
# Exemple pour le mot "Il" en d√©but de phrase
variables_inconnues = {
    "choix_casse": {
        "casse_originale": "Il",
        "position_phrase": "debut",
        "justification_inconnue": True,
        "alternatives_possibles": ["il", "IL"],
        "intention_locuteur": "√†_determiner"
    }
}
```

```python
# Exemple pour une ponctuation finale
variables_inconnues = {
    "choix_ponctuation_finale": {
        "type_choisi": "!",
        "alternatives_possibles": [".", "?", "!"],
        "niveau_emphase": "√†_analyser",
        "intention_communicative": "exclamation_ou_surprise"
    }
}
```

## Contexte et Tra√ßabilit√©

### M√©tadonn√©es de Locuteur

```python
# Exemple complet de contextualisation
element = ElementLinguistique(
    id="elem_92d69b9f",
    contenu="Il",
    type_element="mot_majuscule",
    # ... autres champs ...
    locuteur="conteur_traditionnel",
    contexte_situationnel="conte_oral_familial",
    moment_traitement="2025-09-22T08:53:36.984510",
    version_pipeline="v7.1-Enhanced",
    etat_modele="TokenisateurComplet_v7.1-Enhanced_2025-09-22T08:53:36.978952"
)
```

### Support des Traductions

Pour un texte traduit, ajout des m√©tadonn√©es de traduction :

```python
element.traducteur_original = "traducteur_professionnel_anonyme"
element.contexte_traduction = "traduction_litteraire_francais_vers_anglais"
element.moment_traduction = "2025-09-22T08:53:36.984510"
```

Cela permet de revenir sur les choix du traducteur et de comprendre les filtres appliqu√©s.

## Analyse Fonctionnelle

### D√©tection de Fonction Grammaticale

```python
def _analyser_fonction_grammaticale(self, contenu: str, ctx_gauche: str, 
                                  ctx_droit: str, langue: str) -> Tuple[str, float]:
    """Analyse contextuelle de la fonction grammaticale"""
    
    # Articles par langue
    articles = {
        'fr': ['le', 'la', 'les', 'un', 'une', 'des', 'du', 'de'],
        'en': ['the', 'a', 'an'],
        'de': ['der', 'die', 'das', 'ein', 'eine', 'einen']
    }
    
    contenu_lower = contenu.lower()
    
    if contenu_lower in articles.get(langue, []):
        return "article", 0.9
    elif contenu in ['.', '!', '?']:
        return "ponctuation_finale", 1.0
    elif contenu.isupper() and len(contenu) > 1:
        return "nom_propre_probable", 0.7
    elif contenu[0].isupper():
        return "debut_phrase_ou_nom_propre", 0.6
    else:
        return "element_lexical", 0.5
```

### G√©n√©ration d'Hypoth√®ses S√©mantiques

```python
def _generer_hypotheses_semantiques(self, elements: List[ElementLinguistique], 
                                  langue: str) -> List[Dict[str, Any]]:
    """G√©n√®re des hypoth√®ses pour investigation future"""
    hypotheses = []
    
    # Analyse de l'intention communicative
    ponctuation_finale = [e for e in elements if e.contenu in ['.', '!', '?']]
    if ponctuation_finale:
        type_ponct = ponctuation_finale[-1].contenu
        intention = {
            '.': "d√©clarative/neutre",
            '!': "exclamative/emphase", 
            '?': "interrogative/questionnement"
        }[type_ponct]
        
        hypotheses.append({
            "type": "intention_communicative",
            "hypothese": f"Intention {intention}",
            "niveau_confiance": 0.8,
            "elements_support": [type_ponct],
            "investigation_requise": False
        })
    
    # Analyse du registre de langue
    majuscules = [e for e in elements if e.type_element == "mot_majuscule"]
    if len(majuscules) > 1:
        hypotheses.append({
            "type": "registre_langue",
            "hypothese": "Registre formel possible (plusieurs majuscules)",
            "niveau_confiance": 0.6,
            "elements_support": [e.contenu for e in majuscules],
            "investigation_requise": True
        })
    
    return hypotheses
```

## Exemples Pratiques

### Exemple 1 : Phrase Simple

**Input** : `"Il √©tait une fois une reine."`

**Analyse d√©taill√©e** :

```text
üîç √âL√âMENTS D√âTAILL√âS:
  1. 'Il' [mot_majuscule] (debut_phrase_ou_nom_propre, 0.6)
     üè∑Ô∏è √âtiquettes: INCERTAIN
     ‚ùì Variables: {"choix_casse": {"position_phrase": "debut", "justification_inconnue": true}}

  2. ' ' [espace] (element_lexical, 0.5)
     üè∑Ô∏è √âtiquettes: INCERTAIN, SEMANTIQUE_A_DETERMINER, CARACTERE_ISOLE_SIGNIFICATION_INCONNUE

  3. '√©tait' [mot_minuscule] (element_lexical, 0.5)
     üè∑Ô∏è √âtiquettes: INCERTAIN, SEMANTIQUE_A_DETERMINER
     ‚ùì Variables: {"choix_casse": {"casse_originale": "√©tait"}}

  ... (continue pour tous les √©l√©ments)

‚ö†Ô∏è √âL√âMENTS NON COMPRIS:
   ‚Ä¢ Il (certitude: 0.6)
   ‚Ä¢   (certitude: 0.5) 
   ‚Ä¢ √©tait (certitude: 0.5)
   ‚Ä¢ fois (certitude: 0.5)
   ‚Ä¢ reine (certitude: 0.5)

üí° HYPOTH√àSES S√âMANTIQUES:
   ‚Ä¢ intention_communicative: Intention d√©clarative/neutre (confiance: 0.8)
```

### Exemple 2 : Phrase Complexe

**Input** : `"Dr. Smith's cat‚Äîwhat a story!"`

**D√©fis identifi√©s** :
- `Dr.` : Titre honorifique avec point
- `Smith's` : Nom propre avec apostrophe possessive
- `‚Äî` : Tiret cadratin (√©l√©ment sp√©cial)
- `!` : Ponctuation exclamative

**Traitement** :
```text
üîç √âL√âMENTS D√âTAILL√âS:
  1. 'Dr' [mot_majuscule] (debut_phrase_ou_nom_propre, 0.6)
  2. '.' [ponctuation] (ponctuation_finale, 1.0)
     ‚ùì Variables: {"usage_abbreviation": true, "fin_phrase": false}
  3. ' ' [espace] (element_lexical, 0.5)
  4. 'Smith' [mot_majuscule] (debut_phrase_ou_nom_propre, 0.6)
  5. ''' [ponctuation] (element_lexical, 0.5)
     üè∑Ô∏è √âtiquettes: CARACTERE_ISOLE_SIGNIFICATION_INCONNUE
  6. 's' [mot_minuscule] (element_lexical, 0.5)
     ‚ùì Variables: {"marque_possessive": "probable"}
  9. '‚Äî' [element_special] (element_lexical, 0.5)
     üè∑Ô∏è √âtiquettes: ELEMENT_SPECIAL_NON_CATEGORISE
 15. '!' [ponctuation] (ponctuation_finale, 1.0)
     ‚ùì Variables: {"choix_ponctuation_finale": {"intention": "emphase"}}
```

## Patterns de Conservation

### Espaces Significatifs
```python
# Conservation des espaces multiples
"word1  word2"  # Deux espaces ‚Üí potentiellement significatif
"word1   word2" # Trois espaces ‚Üí emphasis possible
```

### Choix de Casse
```python
# Variables document√©es pour la casse
{
    "choix_casse": {
        "original": "iPhone",      # Casse mixte
        "standard": "iphone",      # Normalisation possible
        "justification": "marque_commerciale",
        "preservation_requise": True
    }
}
```

### Ponctuation Stylistique
```python
# Ponctuation non standard
"Vraiment???"  # Triple point d'interrogation
"Non..."       # Points de suspension
"C'est‚Äîcomment dire‚Äîcompliqu√©"  # Tirets d'incise
```

## Sauvegarde et Tra√ßabilit√©

### Format de Sauvegarde

```json
{
  "phrase_originale": "Il √©tait une fois une reine.",
  "langue": "fr",
  "elements": [
    {
      "id": "92d69b9f",
      "contenu": "Il",
      "type_element": "mot_majuscule",
      "position_absolue": 0,
      "position_relative": 0,
      "contexte_gauche": "",
      "contexte_droit": " √©tait ",
      "langue_detectee": "fr",
      "probable_fonction_grammaticale": "debut_phrase_ou_nom_propre",
      "niveau_certitude": 0.6,
      "etiquettes_temporaires": ["INCERTAIN"],
      "variables_inconnues": {
        "choix_casse": {
          "casse_originale": "Il",
          "position_phrase": "debut",
          "justification_inconnue": true
        }
      },
      "locuteur": "conteur_traditionnel",
      "contexte_situationnel": "conte_oral",
      "moment_traitement": "2025-09-22T08:53:36.984510",
      "version_pipeline": "v7.1-Enhanced",
      "etat_modele": "TokenisateurComplet_v7.1-Enhanced_2025-09-22T08:53:36.978952"
    }
  ],
  "timestamp_analyse": "2025-09-22T08:53:36.984510",
  "version_analyseur": "v7.1-Enhanced"
}
```

## Int√©gration avec le Pipeline

### Interface Standard

```python
class TokenisateurCompletContextuel:
    def tokeniser_phrase_complete(self, phrase: str, langue: str, 
                                contexte_locuteur: str = "inconnu",
                                contexte_situationnel: str = "analyse_generale",
                                traducteur: str = None) -> ContextePhrase:
        """Point d'entr√©e principal pour la tokenisation compl√®te"""
        # Impl√©mentation compl√®te...
```

### Sortie Structur√©e

```python
@dataclass
class ContextePhrase:
    phrase_originale: str
    langue: str
    elements: List[ElementLinguistique]
    structure_syntaxique: Dict[str, Any]
    elements_non_compris: List[str]
    hypotheses_semantiques: List[Dict[str, Any]]
    timestamp_analyse: str
    version_analyseur: str
```

## Conclusion

Cette approche de tokenisation contextuelle compl√®te garantit qu'aucune information n'est perdue lors du traitement initial, tout en pr√©parant le terrain pour des analyses futures plus approfondies. Elle constitue la base solide sur laquelle s'appuient les autres composants du pipeline v7.3.

---

*Documentation technique v7.1*  
*Date : 22 septembre 2025*