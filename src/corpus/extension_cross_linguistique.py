#!/usr/bin/env python3
"""
üåê EXTENSION CROSS-LINGUISTIQUE POLYS√âMIE DHƒÄTU
Adaptations allemand/chinois avec patterns linguistiques sp√©cifiques
Support multi-langues pour r√©solution polys√©mie contextuelle
"""

import json
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from collections import Counter

# Import algorithme base
try:
    from resolution_polysemie_contextuelle import ResolveurPolysemieContextuelle, CandidatDecomposition, AnalysePolysemie
    from integration_complete_dhatu_trio import SystemeDhatuUnifie
except ImportError as e:
    print(f"‚ö†Ô∏è Erreur import: {e}")
    print("Modules base requis")
    exit(1)


@dataclass
class AdaptationLinguistique:
    """Configuration adaptation linguistique sp√©cifique"""
    langue: str
    code_iso: str
    patterns_modaux: Dict[str, List[str]]
    patterns_aspectuels: Dict[str, List[str]] 
    patterns_quantitatifs: Dict[str, List[str]]
    structures_syntaxiques: List[str]
    ordre_mots: str  # SOV, SVO, VSO, etc.
    specificites_culturelles: List[str]


@dataclass
class ResultatCrossLinguistique:
    """R√©sultat analyse cross-linguistique"""
    expression_originale: str
    langue: str
    traductions_equivalentes: Dict[str, str]  # langue -> traduction
    analyses_par_langue: Dict[str, AnalysePolysemie]
    coherence_cross_linguistique: float
    divergences_culturelles: List[str]
    recommandations_adaptation: List[str]


class ExtensionCrossLinguistique:
    """Extension multilingue pour r√©solution polys√©mie dhƒÅtu"""
    
    def __init__(self):
        self.resolveur_base = ResolveurPolysemieContextuelle()
        
        # Adaptations linguistiques
        self.adaptations = {
            "fr": self._creer_adaptation_francais(),
            "de": self._creer_adaptation_allemand(), 
            "zh": self._creer_adaptation_chinois(),
            "en": self._creer_adaptation_anglais()
        }
        
        # Dictionnaires traduction concepts dhƒÅtu
        self.lexiques_dhatu = {
            "MODAL": {
                "fr": ["modal", "possible", "probable", "certain", "n√©cessaire"],
                "de": ["modal", "m√∂glich", "wahrscheinlich", "sicher", "notwendig"],
                "zh": ["ÂèØËÉΩ", "Â§ßÊ¶Ç", "ËÇØÂÆö", "ÂøÖÈ°ª", "Â∫îËØ•"],
                "en": ["modal", "possible", "probable", "certain", "necessary"]
            },
            "ASPECT": {
                "fr": ["aspect", "commencer", "continuer", "finir", "progresser"],
                "de": ["aspekt", "anfangen", "fortsetzen", "beenden", "fortschreiten"],
                "zh": ["ÂºÄÂßã", "ÁªßÁª≠", "ÂÆåÊàê", "ËøõË°å", "ÁªìÊùü"],
                "en": ["aspect", "begin", "continue", "finish", "progress"]
            },
            "QUANT": {
                "fr": ["quantit√©", "beaucoup", "peu", "plusieurs", "nombreux"],
                "de": ["quantit√§t", "viel", "wenig", "mehrere", "zahlreich"],
                "zh": ["Êï∞Èáè", "ÂæàÂ§ö", "ÂæàÂ∞ë", "Âá†‰∏™", "ËÆ∏Â§ö"],
                "en": ["quantity", "much", "little", "several", "numerous"]
            }
        }
        
        # Patterns polys√©mie cross-linguistiques
        self.patterns_universels = {
            "modal_quant": {
                "fr": ["probablement beaucoup", "certainement nombreux", "peut-√™tre plusieurs"],
                "de": ["wahrscheinlich viel", "sicher zahlreich", "vielleicht mehrere"],
                "zh": ["Â§ßÊ¶ÇÂæàÂ§ö", "ËÇØÂÆöËÆ∏Â§ö", "ÂèØËÉΩÂá†‰∏™"],
                "en": ["probably much", "certainly numerous", "maybe several"]
            },
            "aspect_modal": {
                "fr": ["commence peut-√™tre", "va certainement", "pourrait continuer"],
                "de": ["f√§ngt vielleicht an", "wird sicher", "k√∂nnte fortsetzen"],
                "zh": ["ÂèØËÉΩÂºÄÂßã", "ËÇØÂÆö‰ºö", "ÂèØËÉΩÁªßÁª≠"],
                "en": ["maybe begins", "will certainly", "might continue"]
            },
            "aspect_quant": {
                "fr": ["de plus en plus", "plusieurs fois", "beaucoup progresser"],
                "de": ["immer mehr", "mehrmals", "viel fortschreiten"],
                "zh": ["Ë∂äÊù•Ë∂äÂ§ö", "Â§öÊ¨°", "ÂæàÂ§öËøõÊ≠•"],
                "en": ["more and more", "several times", "much progress"]
            }
        }
        
        # M√©triques validation
        self.metriques_cross = {
            "coherence_totale": 0.0,
            "divergences_par_langue": {},
            "patterns_universels_valides": 0,
            "adaptations_reussies": 0
        }
    
    def _creer_adaptation_francais(self) -> AdaptationLinguistique:
        """Adaptation base fran√ßais (r√©f√©rence)"""
        return AdaptationLinguistique(
            langue="Fran√ßais",
            code_iso="fr",
            patterns_modaux={
                "epistemique": ["semble", "para√Æt", "sugg√®re", "indique", "montre"],
                "deontique": ["doit", "faut", "n√©cessaire", "requis", "obligatoire"],
                "dynamique": ["peut", "capable", "parvient", "r√©ussit", "arrive"]
            },
            patterns_aspectuels={
                "inceptif": ["commence", "d√©bute", "entame", "initie", "d√©marre"],
                "progressif": ["continue", "poursuit", "progresse", "avance", "d√©veloppe"],
                "conclusif": ["termine", "finit", "ach√®ve", "conclut", "finalise"]
            },
            patterns_quantitatifs={
                "cardinale": ["un", "deux", "trois", "dix", "cent", "exactement"],
                "approximative": ["environ", "vers", "pr√®s de", "autour de", "approximativement"],
                "comparative": ["plus", "moins", "autant", "davantage", "sup√©rieur"]
            },
            structures_syntaxiques=["SVO", "compl√©ment_postpos√©"],
            ordre_mots="SVO",
            specificites_culturelles=["politesse_conditionnelle", "nuances_subtiles"]
        )
    
    def _creer_adaptation_allemand(self) -> AdaptationLinguistique:
        """Adaptation sp√©cifique allemand"""
        return AdaptationLinguistique(
            langue="Deutsch",
            code_iso="de",
            patterns_modaux={
                "epistemique": ["scheint", "erscheint", "deutet", "zeigt", "weist"],
                "deontique": ["muss", "soll", "notwendig", "erforderlich", "verpflichtend"],
                "dynamique": ["kann", "vermag", "imstande", "f√§hig", "schafft"]
            },
            patterns_aspectuels={
                "inceptif": ["beginnt", "f√§ngt an", "startet", "initiiert", "er√∂ffnet"],
                "progressif": ["setzt fort", "macht weiter", "entwickelt", "schreitet fort"],
                "conclusif": ["beendet", "schlie√üt ab", "vollendet", "finalisiert", "komplettiert"]
            },
            patterns_quantitatifs={
                "cardinale": ["eins", "zwei", "drei", "zehn", "hundert", "genau"],
                "approximative": ["etwa", "ungef√§hr", "rund", "circa", "ann√§hernd"],
                "comparative": ["mehr", "weniger", "gleich", "gr√∂√üer", "kleiner"]
            },
            structures_syntaxiques=["SOV_subordonn√©e", "V2_principale", "s√©parable_verbes"],
            ordre_mots="V2/SOV",
            specificites_culturelles=["pr√©cision_technique", "compos√©s_complexes", "modalit√©_forte"]
        )
    
    def _creer_adaptation_chinois(self) -> AdaptationLinguistique:
        """Adaptation sp√©cifique chinois"""
        return AdaptationLinguistique(
            langue="‰∏≠Êñá",
            code_iso="zh",
            patterns_modaux={
                "epistemique": ["‰ºº‰πé", "Â•ΩÂÉè", "ÂèØËÉΩ", "Â§ßÊ¶Ç", "‰πüËÆ∏"],
                "deontique": ["ÂøÖÈ°ª", "Â∫îËØ•", "ÈúÄË¶Å", "Âæó", "Ë¶Å"],
                "dynamique": ["ËÉΩ", "‰ºö", "ÂèØ‰ª•", "ËÉΩÂ§ü", "Êï¢"]
            },
            patterns_aspectuels={
                "inceptif": ["ÂºÄÂßã", "Ëµ∑", "Âßã", "Âàù", "ÂêØ"],
                "progressif": ["Ê≠£Âú®", "ÁªßÁª≠", "ËøõË°å", "ÂèëÂ±ï", "Êé®Ëøõ"],
                "conclusif": ["ÂÆåÊàê", "ÁªìÊùü", "Áªà", "ÊØï", "‰∫Ü"]
            },
            patterns_quantitatifs={
                "cardinale": ["‰∏Ä", "‰∫å", "‰∏â", "ÂçÅ", "Áôæ", "Á°ÆÂàá"],
                "approximative": ["Â§ßÁ∫¶", "Â∑¶Âè≥", "Â∑Æ‰∏çÂ§ö", "Á∫¶", "Âá†‰πé"],
                "comparative": ["Êõ¥", "ËæÉ", "ÊØî", "Ë∂Ö", "‰∏çÂ¶Ç"]
            },
            structures_syntaxiques=["SVO", "classificateurs", "particules_aspectuelles"],
            ordre_mots="SVO",
            specificites_culturelles=["contexte_implicit", "harmonie_sociale", "hi√©rarchie_respect"]
        )
    
    def _creer_adaptation_anglais(self) -> AdaptationLinguistique:
        """Adaptation sp√©cifique anglais"""
        return AdaptationLinguistique(
            langue="English",
            code_iso="en",
            patterns_modaux={
                "epistemique": ["seems", "appears", "suggests", "indicates", "shows"],
                "deontique": ["must", "should", "necessary", "required", "mandatory"],
                "dynamique": ["can", "able", "capable", "manages", "succeeds"]
            },
            patterns_aspectuels={
                "inceptif": ["begins", "starts", "initiates", "commences", "launches"],
                "progressif": ["continues", "progresses", "develops", "advances", "proceeds"],
                "conclusif": ["finishes", "completes", "concludes", "finalizes", "accomplishes"]
            },
            patterns_quantitatifs={
                "cardinale": ["one", "two", "three", "ten", "hundred", "exactly"],
                "approximative": ["about", "around", "roughly", "approximately", "nearly"],
                "comparative": ["more", "less", "as much", "greater", "fewer"]
            },
            structures_syntaxiques=["SVO", "auxiliaires_modaux", "progressif_continu"],
            ordre_mots="SVO",
            specificites_culturelles=["directness", "efficiency", "pragmatic_focus"]
        )
    
    def adapter_contextes_discriminants(self, langue: str) -> Dict[str, List[str]]:
        """Adapter contextes discriminants pour langue sp√©cifique"""
        
        if langue not in self.adaptations:
            return self.resolveur_base.contextes_discriminants  # Fallback fran√ßais
        
        adaptation = self.adaptations[langue]
        contextes_adaptes = {}
        
        # Modal
        contextes_adaptes["modal_epistemique"] = adaptation.patterns_modaux["epistemique"]
        contextes_adaptes["modal_deontique"] = adaptation.patterns_modaux["deontique"] 
        contextes_adaptes["modal_dynamique"] = adaptation.patterns_modaux["dynamique"]
        
        # Aspect
        contextes_adaptes["aspect_inceptif"] = adaptation.patterns_aspectuels["inceptif"]
        contextes_adaptes["aspect_progressif"] = adaptation.patterns_aspectuels["progressif"]
        contextes_adaptes["aspect_conclusif"] = adaptation.patterns_aspectuels["conclusif"]
        
        # Quant
        contextes_adaptes["quant_cardinale"] = adaptation.patterns_quantitatifs["cardinale"]
        contextes_adaptes["quant_approximative"] = adaptation.patterns_quantitatifs["approximative"]
        contextes_adaptes["quant_comparative"] = adaptation.patterns_quantitatifs["comparative"]
        
        return contextes_adaptes
    
    def detecter_langue_expression(self, expression: str, contexte: str = "") -> str:
        """D√©tection automatique langue d'une expression"""
        
        texte_complet = f"{expression} {contexte}".lower()
        scores_langues = {}
        
        # Scoring par langue
        for code_langue, adaptation in self.adaptations.items():
            score = 0.0
            
            # Patterns modaux
            for pattern_list in adaptation.patterns_modaux.values():
                for pattern in pattern_list:
                    if pattern.lower() in texte_complet:
                        score += 2.0
            
            # Patterns aspectuels
            for pattern_list in adaptation.patterns_aspectuels.values():
                for pattern in pattern_list:
                    if pattern.lower() in texte_complet:
                        score += 2.0
            
            # Patterns quantitatifs
            for pattern_list in adaptation.patterns_quantitatifs.values():
                for pattern in pattern_list:
                    if pattern.lower() in texte_complet:
                        score += 2.0
            
            # Lexique dhƒÅtu
            for dhatu_type, lexique_dhatu in self.lexiques_dhatu.items():
                if code_langue in lexique_dhatu:
                    for terme in lexique_dhatu[code_langue]:
                        if terme.lower() in texte_complet:
                            score += 1.0
            
            scores_langues[code_langue] = score
        
        # Langue avec score maximal
        if scores_langues and max(scores_langues.values()) > 0:
            return max(scores_langues, key=scores_langues.get)
        
        return "fr"  # D√©faut fran√ßais
    
    def resoudre_polysemie_multilingue(self, expression: str, contexte: str = "", 
                                     langue_forcee: Optional[str] = None) -> ResultatCrossLinguistique:
        """R√©solution polys√©mie avec support multilingue"""
        
        # D√©tection langue
        langue_detectee = langue_forcee or self.detecter_langue_expression(expression, contexte)
        
        # Adaptation contextes
        contextes_adaptes = self.adapter_contextes_discriminants(langue_detectee)
        
        # R√©solveur adapt√©
        resolveur_adapte = ResolveurPolysemieContextuelle()
        resolveur_adapte.contextes_discriminants = contextes_adaptes
        
        # Analyse principale
        analyse_principale = resolveur_adapte.resoudre_polysemie(expression, contexte)
        
        # Traductions dans autres langues
        traductions = self._generer_traductions_equivalentes(expression, langue_detectee)
        
        # Analyses cross-linguistiques
        analyses_par_langue = {langue_detectee: analyse_principale}
        
        for code_langue, traduction in traductions.items():
            if code_langue != langue_detectee:
                contextes_trad = self.adapter_contextes_discriminants(code_langue)
                resolveur_trad = ResolveurPolysemieContextuelle()
                resolveur_trad.contextes_discriminants = contextes_trad
                
                analyse_trad = resolveur_trad.resoudre_polysemie(traduction, contexte)
                analyses_par_langue[code_langue] = analyse_trad
        
        # Calcul coh√©rence cross-linguistique
        coherence = self._calculer_coherence_cross_linguistique(analyses_par_langue)
        
        # D√©tection divergences
        divergences = self._detecter_divergences_culturelles(analyses_par_langue, langue_detectee)
        
        # Recommandations
        recommandations = self._generer_recommandations_adaptation(analyses_par_langue, langue_detectee)
        
        return ResultatCrossLinguistique(
            expression_originale=expression,
            langue=langue_detectee,
            traductions_equivalentes=traductions,
            analyses_par_langue=analyses_par_langue,
            coherence_cross_linguistique=coherence,
            divergences_culturelles=divergences,
            recommandations_adaptation=recommandations
        )
    
    def _generer_traductions_equivalentes(self, expression: str, langue_source: str) -> Dict[str, str]:
        """G√©n√©rer traductions √©quivalentes dans autres langues"""
        
        traductions = {langue_source: expression}
        
        # Recherche dans patterns universels
        for pattern_type, patterns_par_langue in self.patterns_universels.items():
            if langue_source in patterns_par_langue:
                for expr_pattern in patterns_par_langue[langue_source]:
                    if self._expressions_similaires(expression, expr_pattern):
                        # Traduction dans autres langues
                        for code_langue, patterns_cible in patterns_par_langue.items():
                            if code_langue != langue_source:
                                # Prendre premi√®re traduction correspondante
                                idx = patterns_par_langue[langue_source].index(expr_pattern)
                                if idx < len(patterns_cible):
                                    traductions[code_langue] = patterns_cible[idx]
                        break
        
        # Traductions par substitution lexique dhƒÅtu
        if len(traductions) == 1:  # Pas trouv√© dans patterns
            traductions.update(self._traduire_par_substitution_dhatu(expression, langue_source))
        
        return traductions
    
    def _expressions_similaires(self, expr1: str, expr2: str, seuil: float = 0.6) -> bool:
        """V√©rifier similarit√© entre expressions"""
        mots1 = set(expr1.lower().split())
        mots2 = set(expr2.lower().split())
        
        if not mots1 or not mots2:
            return False
        
        intersection = mots1.intersection(mots2)
        union = mots1.union(mots2)
        
        similarite = len(intersection) / len(union)
        return similarite >= seuil
    
    def _traduire_par_substitution_dhatu(self, expression: str, langue_source: str) -> Dict[str, str]:
        """Traduction par substitution lexique dhƒÅtu"""
        
        traductions = {}
        mots_expression = expression.lower().split()
        
        for code_langue in self.adaptations:
            if code_langue == langue_source:
                continue
            
            mots_traduits = []
            for mot in mots_expression:
                mot_traduit = mot  # D√©faut: garder original
                
                # Recherche dans lexiques dhƒÅtu
                for dhatu_type, lexique in self.lexiques_dhatu.items():
                    if langue_source in lexique and code_langue in lexique:
                        if mot in lexique[langue_source]:
                            idx = lexique[langue_source].index(mot)
                            if idx < len(lexique[code_langue]):
                                mot_traduit = lexique[code_langue][idx]
                                break
                
                mots_traduits.append(mot_traduit)
            
            traductions[code_langue] = " ".join(mots_traduits)
        
        return traductions
    
    def _calculer_coherence_cross_linguistique(self, analyses: Dict[str, AnalysePolysemie]) -> float:
        """Calculer coh√©rence entre analyses multilingues"""
        
        if len(analyses) < 2:
            return 1.0
        
        scores_coherence = []
        analyses_liste = list(analyses.values())
        
        # Comparaison paires d'analyses
        for i in range(len(analyses_liste)):
            for j in range(i + 1, len(analyses_liste)):
                analyse1 = analyses_liste[i]
                analyse2 = analyses_liste[j]
                
                # Coh√©rence dhƒÅtu impliqu√©s
                if (analyse1.candidat_optimal and analyse2.candidat_optimal):
                    dhatu1 = set(analyse1.candidat_optimal.dhatu_impliques)
                    dhatu2 = set(analyse2.candidat_optimal.dhatu_impliques)
                    
                    if dhatu1 and dhatu2:
                        coherence_dhatu = len(dhatu1.intersection(dhatu2)) / len(dhatu1.union(dhatu2))
                        scores_coherence.append(coherence_dhatu)
                
                # Coh√©rence types polys√©mie
                if analyse1.type_polysemie == analyse2.type_polysemie:
                    scores_coherence.append(0.5)  # Bonus type identique
        
        return sum(scores_coherence) / len(scores_coherence) if scores_coherence else 0.0
    
    def _detecter_divergences_culturelles(self, analyses: Dict[str, AnalysePolysemie], langue_ref: str) -> List[str]:
        """D√©tecter divergences culturelles entre langues"""
        
        divergences = []
        
        if langue_ref not in analyses:
            return divergences
        
        analyse_ref = analyses[langue_ref]
        
        for code_langue, analyse in analyses.items():
            if code_langue == langue_ref:
                continue
            
            adaptation = self.adaptations.get(code_langue)
            if not adaptation:
                continue
            
            # Divergence confiance
            if analyse_ref.candidat_optimal and analyse.candidat_optimal:
                diff_confiance = abs(analyse_ref.confiance_resolution - analyse.confiance_resolution)
                if diff_confiance > 0.3:
                    divergences.append(f"Confiance divergente {langue_ref}‚Üî{code_langue}: {diff_confiance:.2f}")
            
            # Divergence dhƒÅtu
            if (analyse_ref.candidat_optimal and analyse.candidat_optimal):
                dhatu_ref = set(analyse_ref.candidat_optimal.dhatu_impliques)
                dhatu_cible = set(analyse.candidat_optimal.dhatu_impliques)
                
                if dhatu_ref != dhatu_cible:
                    divergences.append(f"DhƒÅtu divergents {langue_ref}‚Üî{code_langue}: {dhatu_ref} vs {dhatu_cible}")
            
            # Divergences sp√©cificit√©s culturelles
            for spec in adaptation.specificites_culturelles:
                if "pr√©cision" in spec and analyse.confiance_resolution > analyse_ref.confiance_resolution:
                    divergences.append(f"Pr√©cision culturelle {code_langue}: +{analyse.confiance_resolution - analyse_ref.confiance_resolution:.2f}")
        
        return divergences
    
    def _generer_recommandations_adaptation(self, analyses: Dict[str, AnalysePolysemie], langue_ref: str) -> List[str]:
        """G√©n√©rer recommandations adaptation cross-linguistique"""
        
        recommandations = []
        
        # Coh√©rence globale
        coherence = self._calculer_coherence_cross_linguistique(analyses)
        
        if coherence < 0.5:
            recommandations.append("Am√©liorer coh√©rence cross-linguistique (patterns universels)")
        
        if coherence > 0.8:
            recommandations.append("Excellente coh√©rence - syst√®me transf√©rable")
        
        # Recommendations par langue
        for code_langue, analyse in analyses.items():
            if code_langue == langue_ref:
                continue
            
            adaptation = self.adaptations.get(code_langue)
            if not adaptation:
                continue
            
            # Confiance faible
            if analyse.confiance_resolution < 0.3:
                recommandations.append(f"Enrichir contextes discriminants {adaptation.langue}")
            
            # Polys√©mie non r√©solue
            if analyse.type_polysemie == "ambigue":
                recommandations.append(f"Ajouter patterns sp√©cifiques {adaptation.langue}")
            
            # Adaptation syntaxique
            if adaptation.ordre_mots != "SVO":
                recommandations.append(f"Adapter ordre mots {adaptation.langue}: {adaptation.ordre_mots}")
        
        return recommandations
    
    def tester_extension_multilingue(self, expressions_test: List[Tuple[str, str, str]]) -> Dict:
        """Test extension multilingue sur corpus d'expressions"""
        
        resultats = []
        stats_globales = {
            "total_expressions": len(expressions_test),
            "langues_detectees": Counter(),
            "coherence_moyenne": 0.0,
            "divergences_totales": 0,
            "adaptations_reussies": 0
        }
        
        print(f"üåê Test extension cross-linguistique: {len(expressions_test)} expressions")
        
        for i, (expression, contexte, langue_attendue) in enumerate(expressions_test):
            if i % 10 == 0:
                print(f"   Progression: {i}/{len(expressions_test)}")
            
            resultat = self.resoudre_polysemie_multilingue(expression, contexte)
            resultats.append(asdict(resultat))
            
            # Stats
            stats_globales["langues_detectees"][resultat.langue] += 1
            stats_globales["coherence_moyenne"] += resultat.coherence_cross_linguistique
            stats_globales["divergences_totales"] += len(resultat.divergences_culturelles)
            
            if resultat.coherence_cross_linguistique > 0.6:
                stats_globales["adaptations_reussies"] += 1
        
        # Moyennes
        if stats_globales["total_expressions"] > 0:
            stats_globales["coherence_moyenne"] /= stats_globales["total_expressions"]
        
        stats_globales["taux_adaptation"] = (stats_globales["adaptations_reussies"] / 
                                           stats_globales["total_expressions"]) * 100
        
        return {
            "statistiques_globales": stats_globales,
            "resultats_detailles": resultats[:20],  # Sample
            "metriques_cross": self.metriques_cross
        }


def main():
    """Test extension cross-linguistique polys√©mie dhƒÅtu"""
    print("üåê EXTENSION CROSS-LINGUISTIQUE POLYS√âMIE DHƒÄTU")
    print("Adaptations allemand/chinois + patterns universels")
    print("="*60)
    
    # Initialisation extension
    extension = ExtensionCrossLinguistique()
    
    # Expressions test multilingues
    expressions_test = [
        # Fran√ßais
        ("probablement beaucoup", "Dans cette recherche scientifique", "fr"),
        ("commence peut-√™tre", "Le processus d'analyse", "fr"),
        ("certainement nombreux", "Les participants sont", "fr"),
        
        # Allemand
        ("wahrscheinlich viel", "In dieser wissenschaftlichen Forschung", "de"),
        ("f√§ngt vielleicht an", "Der Analyseprozess", "de"),
        ("sicher zahlreich", "Die Teilnehmer sind", "de"),
        
        # Chinois
        ("Â§ßÊ¶ÇÂæàÂ§ö", "Âú®Ëøô‰∏™ÁßëÂ≠¶Á†îÁ©∂‰∏≠", "zh"),
        ("ÂèØËÉΩÂºÄÂßã", "ÂàÜÊûêËøáÁ®ã", "zh"),
        ("ËÇØÂÆöËÆ∏Â§ö", "ÂèÇ‰∏éËÄÖ", "zh"),
        
        # Anglais
        ("probably much", "In this scientific research", "en"),
        ("maybe begins", "The analysis process", "en"),
        ("certainly numerous", "The participants are", "en"),
        
        # Expressions mixtes/ambigu√´s
        ("ÂæàÂèØËÉΩ beaucoup", "Contexte mixte", "zh"),
        ("peut-√™tre Â§ö", "Mixed context", "fr")
    ]
    
    print(f"üìä Test sur {len(expressions_test)} expressions multilingues")
    
    # Test extension massive
    resultats = extension.tester_extension_multilingue(expressions_test)
    
    # Affichage r√©sultats
    stats = resultats["statistiques_globales"]
    print(f"\nüìà R√âSULTATS EXTENSION CROSS-LINGUISTIQUE:")
    print("="*43)
    print(f"‚úÖ Expressions test√©es: {stats['total_expressions']}")
    print(f"‚úÖ Adaptations r√©ussies: {stats['adaptations_reussies']} ({stats['taux_adaptation']:.1f}%)")
    print(f"‚úÖ Coh√©rence moyenne: {stats['coherence_moyenne']:.3f}")
    print(f"‚úÖ Divergences totales: {stats['divergences_totales']}")
    
    print(f"\nüåç LANGUES D√âTECT√âES:")
    print("="*18)
    for langue, count in stats["langues_detectees"].items():
        pourcentage = (count / stats['total_expressions']) * 100
        langue_nom = extension.adaptations[langue].langue if langue in extension.adaptations else langue
        print(f"   {langue_nom} ({langue}): {count} ({pourcentage:.1f}%)")
    
    # Exemples r√©ussites cross-linguistiques
    print(f"\nüéØ EXEMPLES COH√âRENCE CROSS-LINGUISTIQUE:")
    print("="*39)
    exemples_coherents = [r for r in resultats["resultats_detailles"] 
                         if r['coherence_cross_linguistique'] > 0.7][:3]
    
    for exemple in exemples_coherents:
        expr = exemple['expression_originale']
        langue = exemple['langue']
        coherence = exemple['coherence_cross_linguistique']
        traductions = exemple['traductions_equivalentes']
        
        print(f"‚úÖ '{expr}' ({langue}) - Coh√©rence: {coherence:.2f}")
        for lang_code, trad in traductions.items():
            if lang_code != langue:
                lang_nom = extension.adaptations[lang_code].langue if lang_code in extension.adaptations else lang_code
                print(f"   ‚Üí {lang_nom}: '{trad}'")
    
    # Sauvegarde
    fichier_resultats = "extension_cross_linguistique_resultats.json"
    with open(fichier_resultats, "w", encoding="utf-8") as f:
        json.dump(resultats, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ R√©sultats sauvegard√©s: {fichier_resultats}")
    
    # Validation objectifs
    taux_adaptation = stats['taux_adaptation']
    coherence_moyenne = stats['coherence_moyenne']
    objectif_adaptation = 60.0  # 60% adaptations r√©ussies
    objectif_coherence = 0.5   # 50% coh√©rence cross-linguistique
    
    print(f"\nüéä VALIDATION EXTENSION CROSS-LINGUISTIQUE:")
    print("="*42)
    print(f"üéØ Taux adaptation: {taux_adaptation:.1f}%")
    print(f"üéØ Objectif adaptation: {objectif_adaptation}%")
    print(f"üéØ Coh√©rence moyenne: {coherence_moyenne:.3f}")
    print(f"üéØ Objectif coh√©rence: {objectif_coherence}")
    
    success_adaptation = taux_adaptation >= objectif_adaptation
    success_coherence = coherence_moyenne >= objectif_coherence
    
    print(f"üéØ Status adaptation: {'‚úÖ OBJECTIF ATTEINT' if success_adaptation else '‚ö†Ô∏è √Ä am√©liorer'}")
    print(f"üéØ Status coh√©rence: {'‚úÖ OBJECTIF ATTEINT' if success_coherence else '‚ö†Ô∏è √Ä am√©liorer'}")
    
    if success_adaptation and success_coherence:
        print(f"\nüöÄ EXTENSION CROSS-LINGUISTIQUE OP√âRATIONNELLE!")
        print("Support multilingue pr√™t pour production")
    else:
        print(f"\n‚ö†Ô∏è Optimisations recommand√©es:")
        if not success_adaptation:
            print("- Enrichir patterns linguistiques sp√©cifiques")
            print("- Am√©liorer d√©tection automatique langue")
        if not success_coherence:
            print("- D√©velopper patterns universels")
            print("- Calibrer weights cross-linguistiques")
    
    return extension, resultats

if __name__ == "__main__":
    extension, resultats = main()