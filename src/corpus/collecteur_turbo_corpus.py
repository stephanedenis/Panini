#!/usr/bin/env python3
import time, json, random
from datetime import datetime
from pathlib import Path

workspace = Path('/home/stephane/GitHub/PaniniFS-Research')
session_id = f"turbo_corpus_{int(time.time())}"
results_dir = workspace / f'turbo_corpus_{session_id}'
results_dir.mkdir(exist_ok=True)

dhatu_list = ['gam', 'kar', 'k·πõ', 'bh≈´', 'as', 'vid', '≈õru', 'pac', 'yaj', 'dhƒÅ']

print(f"üìä Collecteur Corpus TURBO d√©marr√© - Session {session_id}")

batch_count = 0
while True:
    batch_count += 1
    corpus_entries = []
    
    for idx in range(25):  # 25 entr√©es par batch
        dhatu = random.choice(dhatu_list)
        entry = {
            'id': f"turbo_{int(time.time())}_{idx}",
            'dhatu': dhatu,
            'text': f"{dhatu}‡§§‡§ø ‡§ß‡§æ‡§§‡•Å‡§É‡•§ ‡§§‡•Å‡§∞‡•ç‡§¨‡•ã ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£‡§Æ‡•ç‡•§",
            'language': 'sanskrit',
            'quality_score': random.uniform(0.85, 0.98),
            'processing_mode': 'turbo',
            'generated_at': datetime.now().isoformat()
        }
        corpus_entries.append(entry)
    
    corpus_file = results_dir / f'turbo_corpus_batch_{batch_count}.json'
    with open(corpus_file, 'w', encoding='utf-8') as f:
        json.dump({
            'session_id': session_id,
            'batch_number': batch_count,
            'entries_count': len(corpus_entries),
            'entries': corpus_entries,
            'timestamp': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)
    
    print(f"üìä Batch TURBO {batch_count} g√©n√©r√© - 25 entr√©es corpus")
    time.sleep(90)  # 1.5 minutes
