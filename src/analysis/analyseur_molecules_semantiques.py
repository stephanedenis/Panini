#!/usr/bin/env python3
"""
ANALYSEUR DE MOLÃ‰CULES SÃ‰MANTIQUES CONTEXTUELLES
===============================================

DÃ©compose tout mot non-atomique en molÃ©cules dhÄtu et capture
toutes les interprÃ©tations possibles selon le contexte.

Approche : Analyse compositionnelle + contexte + ambiguÃ¯tÃ©s prÃ©servÃ©es
"""

import json
import re
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class InterpretationContextuelle:
    """Une interprÃ©tation possible d'un mot selon le contexte."""
    interpretation_id: str
    contexte: str
    dhatu_constituants: List[str]
    force_semantique: float
    evidences: List[str]  # Preuves contextuelles
    ambiguites: List[str]  # AmbiguÃ¯tÃ©s dÃ©tectÃ©es

@dataclass
class MoleculeSemantiqueComplete:
    """MolÃ©cule sÃ©mantique complÃ¨te avec toutes ses interprÃ©tations."""
    mot_source: str
    langue: str
    interpretations_possibles: List[InterpretationContextuelle]
    dhatu_principaux: List[str]
    niveau_complexite: int  # 1=quasi-atomique, 5=trÃ¨s complexe
    patterns_cross_linguistiques: Dict[str, str]

class AnalyseurMoleculesSemantiquesConte:
    """Analyseur spÃ©cialisÃ© pour les molÃ©cules sÃ©mantiques des contes."""
    
    def __init__(self):
        self.dhatu_atomiques = {
            'EXIST': 'existence, Ãªtre, prÃ©sence ontologique',
            'COMM': 'communication, expression, transmission',
            'TRANS': 'transformation, changement d\'Ã©tat',
            'DECIDE': 'dÃ©cision, choix, volition',
            'EVAL': 'Ã©valuation, jugement, apprÃ©ciation',
            'GROUP': 'relation, association, groupement',
            'ITER': 'rÃ©pÃ©tition, itÃ©ration, cyclicitÃ©',
            'LOCATE': 'localisation, position, direction',
            'SEQ': 'sÃ©quence, ordre, progression'
        }
        
        self.molecules_analysees = {}
        self.patterns_compositionnels = {}
        self.contextes_narratifs = {}
        
        self._initialiser_patterns_compositionnels()
        self._initialiser_contextes_narratifs()
    
    def _initialiser_patterns_compositionnels(self):
        """Initialise les patterns de composition sÃ©mantique."""
        
        # Patterns verbo-nominaux
        self.patterns_compositionnels['verbo_nominal'] = {
            'fr': {
                'se_moquait': ['EVAL', 'COMM', 'TRANS'],  # Ã©valuation + communication + action
                'travaillait': ['TRANS', 'ITER', 'EXIST'],  # transformation + rÃ©pÃ©tition + Ãªtre
                'collectait': ['TRANS', 'GROUP', 'ITER'],  # transformation + groupement + rÃ©pÃ©tition
                'cousait': ['TRANS', 'ITER', 'LOCATE'],  # transformation + rÃ©pÃ©tition + localisation
                'verspottete': ['EVAL', 'COMM', 'TRANS'],  # (mÃªme pattern cross-linguistique)
                'arbeitete': ['TRANS', 'ITER', 'EXIST'],
                'sammelte': ['TRANS', 'GROUP', 'ITER']
            },
            'en': {
                'mocked': ['EVAL', 'COMM', 'TRANS'],
                'worked': ['TRANS', 'ITER', 'EXIST'],
                'collected': ['TRANS', 'GROUP', 'ITER'],
                'sewing': ['TRANS', 'ITER', 'LOCATE']
            },
            'de': {
                'verspottete': ['EVAL', 'COMM', 'TRANS'],
                'arbeitete': ['TRANS', 'ITER', 'EXIST'],
                'sammelte': ['TRANS', 'GROUP', 'ITER'],
                'nÃ¤hte': ['TRANS', 'ITER', 'LOCATE']
            }
        }
        
        # Patterns adverbiaux complexes
        self.patterns_compositionnels['adverbial_complexe'] = {
            'fr': {
                'lentement_mais_sÃ»rement': ['EVAL', 'SEQ', 'DECIDE'],  # maniÃ¨re + progression + certitude
                'trÃ¨s_vite': ['EVAL', 'TRANS'],  # intensitÃ© + rapiditÃ©
                'calmement': ['EVAL', 'EXIST'],  # maniÃ¨re + Ã©tat
                'dur_pour': ['EVAL', 'TRANS']  # difficultÃ© + finalitÃ©
            },
            'en': {
                'slowly_but_surely': ['EVAL', 'SEQ', 'DECIDE'],
                'very_fast': ['EVAL', 'TRANS'],
                'calmly': ['EVAL', 'EXIST'],
                'hard_to': ['EVAL', 'TRANS']
            },
            'de': {
                'langsam_aber_sicher': ['EVAL', 'SEQ', 'DECIDE'],
                'sehr_schnell': ['EVAL', 'TRANS'],
                'ruhig': ['EVAL', 'EXIST'],
                'hart_um': ['EVAL', 'TRANS']
            }
        }
        
        # Patterns causaux
        self.patterns_compositionnels['causal'] = {
            'fr': {
                'Ã _cause_de_sa_lenteur': ['EVAL', 'TRANS', 'LOCATE'],  # jugement + causation + attribution
                'pour_l\'hiver': ['TRANS', 'LOCATE', 'SEQ'],  # finalitÃ© + temps + sÃ©quence
                'contre_toi': ['EVAL', 'LOCATE', 'GROUP']  # opposition + direction + relation
            },
            'en': {
                'because_of_its_slowness': ['EVAL', 'TRANS', 'LOCATE'],
                'for_winter': ['TRANS', 'LOCATE', 'SEQ'],
                'against_you': ['EVAL', 'LOCATE', 'GROUP']
            },
            'de': {
                'wegen_ihrer_langsamkeit': ['EVAL', 'TRANS', 'LOCATE'],
                'fÃ¼r_den_winter': ['TRANS', 'LOCATE', 'SEQ'],
                'gegen_dich': ['EVAL', 'LOCATE', 'GROUP']
            }
        }
    
    def _initialiser_contextes_narratifs(self):
        """Initialise les contextes narratifs spÃ©cialisÃ©s."""
        
        self.contextes_narratifs = {
            'ouverture_conte': {
                'marqueurs': ['il Ã©tait une fois', 'once upon a time', 'es war einmal'],
                'dhatu_dominants': ['EVID_NARR', 'SEQ', 'LOCATE'],
                'interpretations_privilegiees': ['narratif_traditionnel', 'temporalite_mythique']
            },
            'dialogue_direct': {
                'marqueurs': ['"', 'Â«', 'Â»', 'dit', 'said', 'sagte'],
                'dhatu_dominants': ['COMM', 'EXIST', 'EVAL'],
                'interpretations_privilegiees': ['parole_directe', 'subjectivite']
            },
            'action_durative': {
                'marqueurs': ['Ã©tait en train', 'was', 'war dabei'],
                'dhatu_dominants': ['TRANS', 'ITER', 'EXIST'],
                'interpretations_privilegiees': ['processus_en_cours', 'durativite']
            },
            'evaluation_qualitative': {
                'marqueurs': ['si', 'so', 'trÃ¨s', 'very', 'sehr'],
                'dhatu_dominants': ['EVAL', 'TRANS'],
                'interpretations_privilegiees': ['intensite', 'qualification']
            },
            'relation_causale': {
                'marqueurs': ['Ã  cause de', 'because of', 'wegen'],
                'dhatu_dominants': ['EVAL', 'TRANS', 'LOCATE'],
                'interpretations_privilegiees': ['causalite', 'attribution']
            }
        }
    
    def analyser_mot_nouveau(self, mot: str, contexte_phrase: str, langue: str) -> MoleculeSemantiqueComplete:
        """Analyse un mot nouveau pour crÃ©er sa molÃ©cule sÃ©mantique."""
        
        logger.info(f"ğŸ”¬ Analyse molÃ©cule: '{mot}' (contexte: '{contexte_phrase[:50]}...')")
        
        # 1. DÃ©tection du contexte narratif
        contexte_detecte = self._detecter_contexte_narratif(contexte_phrase)
        
        # 2. Analyse compositionnelle du mot
        interpretations = self._generer_interpretations_compositionnelles(mot, contexte_detecte, langue)
        
        # 3. Analyse cross-linguistique
        patterns_cross = self._analyser_patterns_cross_linguistiques(mot, langue)
        
        # 4. Ã‰valuation de la complexitÃ©
        niveau_complexite = self._evaluer_complexite_semantique(mot, interpretations)
        
        # 5. Extraction dhÄtu principaux
        dhatu_principaux = self._extraire_dhatu_principaux(interpretations)
        
        molecule = MoleculeSemantiqueComplete(
            mot_source=mot,
            langue=langue,
            interpretations_possibles=interpretations,
            dhatu_principaux=dhatu_principaux,
            niveau_complexite=niveau_complexite,
            patterns_cross_linguistiques=patterns_cross
        )
        
        # Cache pour rÃ©utilisation
        self.molecules_analysees[f"{mot}_{langue}"] = molecule
        
        return molecule
    
    def _detecter_contexte_narratif(self, phrase: str) -> str:
        """DÃ©tecte le contexte narratif principal de la phrase."""
        
        phrase_lower = phrase.lower()
        
        # Recherche par prioritÃ©
        for contexte, details in self.contextes_narratifs.items():
            for marqueur in details['marqueurs']:
                if marqueur in phrase_lower:
                    return contexte
        
        # Contexte par dÃ©faut
        return 'narratif_general'
    
    def _generer_interpretations_compositionnelles(self, mot: str, contexte: str, langue: str) -> List[InterpretationContextuelle]:
        """GÃ©nÃ¨re toutes les interprÃ©tations compositionnelles possibles."""
        
        interpretations = []
        
        # 1. Recherche dans patterns compositionnels
        for categorie, patterns_langue in self.patterns_compositionnels.items():
            if langue in patterns_langue and mot in patterns_langue[langue]:
                dhatu_constituants = patterns_langue[langue][mot]
                
                interpretation = InterpretationContextuelle(
                    interpretation_id=f"{categorie}_{mot}",
                    contexte=contexte,
                    dhatu_constituants=dhatu_constituants,
                    force_semantique=0.9,  # Forte pour patterns connus
                    evidences=[f"pattern_{categorie}", f"contexte_{contexte}"],
                    ambiguites=[]
                )
                interpretations.append(interpretation)
        
        # 2. Analyse morphologique pour mots inconnus
        if not interpretations:
            interpretations.extend(self._analyser_morphologiquement(mot, contexte, langue))
        
        # 3. InterprÃ©tations contextuelles spÃ©cialisÃ©es
        if contexte in self.contextes_narratifs:
            contexte_info = self.contextes_narratifs[contexte]
            
            # InterprÃ©tation biaisÃ©e par le contexte
            interpretation_contextuelle = InterpretationContextuelle(
                interpretation_id=f"contextuel_{contexte}_{mot}",
                contexte=contexte,
                dhatu_constituants=contexte_info['dhatu_dominants'],
                force_semantique=0.7,
                evidences=[f"contexte_narratif_{contexte}"],
                ambiguites=[f"interpretation_biaisee_par_{contexte}"]
            )
            interpretations.append(interpretation_contextuelle)
        
        return interpretations
    
    def _analyser_morphologiquement(self, mot: str, contexte: str, langue: str) -> List[InterpretationContextuelle]:
        """Analyse morphologique pour dÃ©composer un mot inconnu."""
        
        interpretations = []
        
        # Patterns morphologiques par langue
        patterns_morpho = {
            'fr': {
                # Suffixes verbaux
                r'.*ait$': ['TRANS', 'ITER', 'EXIST'],  # imparfait
                r'.*ent$': ['TRANS', 'EXIST'],  # prÃ©sent 3e pluriel
                r'.*er$': ['TRANS'],  # infinitif
                # Suffixes nominaux
                r'.*eur$': ['EVAL', 'EXIST'],  # agent/qualitÃ©
                r'.*ment$': ['EVAL', 'TRANS'],  # adverbe de maniÃ¨re
                r'.*tion$': ['TRANS', 'GROUP']  # action/rÃ©sultat
            },
            'en': {
                r'.*ing$': ['TRANS', 'ITER'],  # progressive
                r'.*ed$': ['TRANS', 'EXIST'],  # passÃ©
                r'.*ly$': ['EVAL', 'TRANS'],  # adverbe
                r'.*ness$': ['EVAL', 'EXIST'],  # qualitÃ©
                r'.*tion$': ['TRANS', 'GROUP']
            },
            'de': {
                r'.*te$': ['TRANS', 'ITER', 'EXIST'],  # prÃ©tÃ©rit
                r'.*en$': ['TRANS', 'EXIST'],  # infinitif/pluriel
                r'.*heit$': ['EVAL', 'EXIST'],  # qualitÃ© abstraite
                r'.*keit$': ['EVAL', 'EXIST'],  # possibilitÃ©/qualitÃ©
                r'.*ung$': ['TRANS', 'GROUP']  # action/rÃ©sultat
            }
        }
        
        if langue in patterns_morpho:
            for pattern, dhatu_probable in patterns_morpho[langue].items():
                if re.match(pattern, mot):
                    interpretation = InterpretationContextuelle(
                        interpretation_id=f"morpho_{pattern}_{mot}",
                        contexte=contexte,
                        dhatu_constituants=dhatu_probable,
                        force_semantique=0.6,  # Moyenne pour analyse morpho
                        evidences=[f"pattern_morphologique_{pattern}"],
                        ambiguites=[f"analyse_morpho_ambigue_{pattern}"]
                    )
                    interpretations.append(interpretation)
        
        # Si aucun pattern trouvÃ©, interprÃ©tation gÃ©nÃ©rique
        if not interpretations:
            interpretation_generique = InterpretationContextuelle(
                interpretation_id=f"generique_{mot}",
                contexte=contexte,
                dhatu_constituants=['EXIST', 'TRANS'],  # DhÄtu les plus probables
                force_semantique=0.3,  # Faible pour gÃ©nÃ©rique
                evidences=['analyse_generique'],
                ambiguites=['interpretation_incertaine', 'dhatu_non_confirmes']
            )
            interpretations.append(interpretation_generique)
        
        return interpretations
    
    def _analyser_patterns_cross_linguistiques(self, mot: str, langue_source: str) -> Dict[str, str]:
        """Analyse les patterns cross-linguistiques pour trouver Ã©quivalents."""
        
        patterns_cross = {}
        
        # Recherche dans tous les patterns compositionnels
        for categorie, patterns_par_langue in self.patterns_compositionnels.items():
            if langue_source in patterns_par_langue:
                if mot in patterns_par_langue[langue_source]:
                    # Chercher Ã©quivalents dans autres langues
                    dhatu_mot = patterns_par_langue[langue_source][mot]
                    
                    for autre_langue, patterns_langue in patterns_par_langue.items():
                        if autre_langue != langue_source:
                            for autre_mot, dhatu_autre in patterns_langue.items():
                                if dhatu_autre == dhatu_mot:  # MÃªme composition dhÄtu
                                    patterns_cross[autre_langue] = autre_mot
        
        return patterns_cross
    
    def _evaluer_complexite_semantique(self, mot: str, interpretations: List[InterpretationContextuelle]) -> int:
        """Ã‰value le niveau de complexitÃ© sÃ©mantique (1-5)."""
        
        # Facteurs de complexitÃ©
        nb_interpretations = len(interpretations)
        nb_ambiguites = sum(len(interp.ambiguites) for interp in interpretations)
        nb_dhatu_moyen = sum(len(interp.dhatu_constituants) for interp in interpretations) / max(1, nb_interpretations)
        
        # Calcul score complexitÃ©
        score_complexite = 1
        
        if nb_interpretations > 3:
            score_complexite += 1
        if nb_ambiguites > 2:
            score_complexite += 1
        if nb_dhatu_moyen > 2:
            score_complexite += 1
        if len(mot) > 10:  # Mots longs souvent plus complexes
            score_complexite += 1
        
        return min(5, score_complexite)
    
    def _extraire_dhatu_principaux(self, interpretations: List[InterpretationContextuelle]) -> List[str]:
        """Extrait les dhÄtu principaux par frÃ©quence pondÃ©rÃ©e."""
        
        dhatu_scores = defaultdict(float)
        
        for interpretation in interpretations:
            poids = interpretation.force_semantique
            for dhatu in interpretation.dhatu_constituants:
                dhatu_scores[dhatu] += poids
        
        # Tri par score dÃ©croissant
        dhatu_tries = sorted(dhatu_scores.items(), key=lambda x: x[1], reverse=True)
        
        # Retour des dhÄtu principaux (score > moyenne)
        if dhatu_tries:
            score_moyen = sum(score for _, score in dhatu_tries) / len(dhatu_tries)
            dhatu_principaux = [dhatu for dhatu, score in dhatu_tries if score >= score_moyen]
            return dhatu_principaux[:5]  # Maximum 5 dhÄtu principaux
        
        return []
    
    def analyser_phrase_complete(self, phrase: str, langue: str) -> Dict[str, MoleculeSemantiqueComplete]:
        """Analyse tous les mots d'une phrase pour crÃ©er les molÃ©cules."""
        
        logger.info(f"ğŸ§ª Analyse phrase complÃ¨te: '{phrase}'")
        
        molecules_phrase = {}
        
        # Nettoyage et tokenisation
        mots = re.findall(r'\w+', phrase.lower())
        
        for mot in mots:
            if len(mot) > 2:  # Ignorer mots trÃ¨s courts
                molecule = self.analyser_mot_nouveau(mot, phrase, langue)
                molecules_phrase[mot] = molecule
        
        return molecules_phrase
    
    def generer_rapport_molecules(self, molecules: Dict[str, MoleculeSemantiqueComplete]) -> str:
        """GÃ©nÃ¨re un rapport dÃ©taillÃ© des molÃ©cules analysÃ©es."""
        
        rapport = f"""
ğŸ§¬ RAPPORT D'ANALYSE MOLÃ‰CULES SÃ‰MANTIQUES
=========================================

ğŸ“Š STATISTIQUES:
   â€¢ MolÃ©cules analysÃ©es: {len(molecules)}
   â€¢ ComplexitÃ© moyenne: {sum(m.niveau_complexite for m in molecules.values()) / len(molecules):.1f}
   â€¢ DhÄtu uniques utilisÃ©s: {len(set().union(*[m.dhatu_principaux for m in molecules.values()]))}

ğŸ”¬ ANALYSE DÃ‰TAILLÃ‰E:
"""
        
        for mot, molecule in molecules.items():
            rapport += f"\nğŸ“ MOT: '{mot}' (ComplexitÃ©: {molecule.niveau_complexite}/5)"
            rapport += f"\n   DhÄtu principaux: {', '.join(molecule.dhatu_principaux)}"
            rapport += f"\n   Patterns cross-linguistiques: {molecule.patterns_cross_linguistiques}"
            
            for i, interp in enumerate(molecule.interpretations_possibles, 1):
                rapport += f"\n   ğŸ¯ InterprÃ©tation {i}: {interp.interpretation_id}"
                rapport += f"\n      Contexte: {interp.contexte}"
                rapport += f"\n      DhÄtu: {interp.dhatu_constituants}"
                rapport += f"\n      Force: {interp.force_semantique:.2f}"
                if interp.ambiguites:
                    rapport += f"\n      âš ï¸ AmbiguÃ¯tÃ©s: {', '.join(interp.ambiguites)}"
        
        return rapport

def tester_analyseur_conte():
    """Test de l'analyseur sur des extraits de contes."""
    
    print("ğŸ§¬ TEST ANALYSEUR MOLÃ‰CULES SÃ‰MANTIQUES")
    print("=" * 50)
    
    analyseur = AnalyseurMoleculesSemantiquesConte()
    
    # Phrases test avec mots complexes
    phrases_test = [
        ("Un liÃ¨vre se moquait d'une tortue Ã  cause de sa lenteur.", "fr"),
        ("The hare worked hard to collect food for winter.", "en"),
        ("Die KÃ¶nigin nÃ¤hte am Fenster wÃ¤hrend des Winters.", "de")
    ]
    
    toutes_molecules = {}
    
    for phrase, langue in phrases_test:
        print(f"\nğŸ” Analyse: {phrase}")
        molecules = analyseur.analyser_phrase_complete(phrase, langue)
        toutes_molecules.update(molecules)
    
    # Rapport complet
    rapport = analyseur.generer_rapport_molecules(toutes_molecules)
    print(rapport)
    
    # Sauvegarde
    resultats = {
        'molecules_analysees': {mot: asdict(mol) for mot, mol in toutes_molecules.items()},
        'statistiques': {
            'total_molecules': len(toutes_molecules),
            'complexite_moyenne': sum(m.niveau_complexite for m in toutes_molecules.values()) / len(toutes_molecules),
            'dhatu_utilises': list(set().union(*[m.dhatu_principaux for m in toutes_molecules.values()]))
        }
    }
    
    with open('analyse_molecules_semantiques_conte.json', 'w', encoding='utf-8') as f:
        json.dump(resultats, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s: analyse_molecules_semantiques_conte.json")

if __name__ == "__main__":
    tester_analyseur_conte()