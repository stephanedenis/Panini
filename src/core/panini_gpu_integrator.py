#!/usr/bin/env python3
"""
Int√©grateur Final GPU + PaniniFS
Combine monitoring temps r√©el et optimisations pour performance maximale
"""

import subprocess
import json
import time
import threading
from pathlib import Path
from datetime import datetime
import signal
import sys


class PaniniGPUIntegrator:
    def __init__(self):
        self.workspace = Path('/home/stephane/GitHub/PaniniFS-Research')
        self.running = True
        self.gpu_stats = {}
        self.monitor_thread = None
        
        # Capture signaux pour arr√™t propre
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        self.log("üéÆ PaniniFS GPU Int√©grateur initialis√©")
    
    def log(self, message):
        """Logging avec timestamp"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        print(f"[{timestamp}] {message}")
    
    def signal_handler(self, signum, frame):
        """Gestion arr√™t propre"""
        self.log("üõë Signal d'arr√™t re√ßu")
        self.running = False
        sys.exit(0)
    
    def start_gpu_monitoring_thread(self):
        """D√©marre monitoring GPU en thread s√©par√©"""
        def monitor_gpu():
            try:
                # Lancer amdgpu_top en mode continu
                process = subprocess.Popen([
                    'amdgpu_top', '--smi'
                ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
                
                while self.running:
                    try:
                        output = process.stdout.readline()
                        if output:
                            self.parse_gpu_output(output.strip())
                        time.sleep(0.1)  # Throttling
                    except Exception as e:
                        self.log(f"‚ùå Erreur monitoring: {e}")
                        break
                
                process.terminate()
                self.log("üõë Thread monitoring GPU arr√™t√©")
                
            except Exception as e:
                self.log(f"‚ùå Erreur d√©marrage monitoring: {e}")
        
        self.monitor_thread = threading.Thread(target=monitor_gpu, daemon=True)
        self.monitor_thread.start()
        self.log("üëÅÔ∏è Thread monitoring GPU d√©marr√©")
    
    def parse_gpu_output(self, output):
        """Parse sortie amdgpu_top"""
        try:
            if 'VRAM' in output and 'GiB' in output:
                # Extraction stats VRAM
                parts = output.split()
                for i, part in enumerate(parts):
                    if 'GiB' in part and i > 0:
                        vram_usage = parts[i-1]
                        if '/' in vram_usage:
                            used, total = vram_usage.split('/')
                            self.gpu_stats['vram_used_mb'] = float(used) * 1024
                            self.gpu_stats['vram_total_mb'] = float(total) * 1024
                            self.gpu_stats['vram_usage_percent'] = (float(used) / float(total)) * 100
                            break
            
            elif 'GPU' in output and '%' in output:
                # Extraction utilisation GPU
                for part in output.split():
                    if '%' in part:
                        try:
                            utilization = float(part.replace('%', ''))
                            self.gpu_stats['gpu_utilization'] = utilization
                            break
                        except ValueError:
                            continue
            
            self.gpu_stats['last_update'] = time.time()
            
        except Exception as e:
            # Ignore parse errors silencieusement
            pass
    
    def get_current_gpu_stats(self):
        """Retourne stats GPU actuelles"""
        return self.gpu_stats.copy()
    
    def optimize_gpu_for_workload(self, workload_type):
        """Optimise GPU pour type de workload"""
        optimization_applied = False
        
        current_stats = self.get_current_gpu_stats()
        vram_usage = current_stats.get('vram_usage_percent', 0)
        gpu_utilization = current_stats.get('gpu_utilization', 0)
        
        self.log(f"üîß Optimisation pour workload: {workload_type}")
        self.log(f"üìä VRAM: {vram_usage:.1f}% | GPU: {gpu_utilization:.1f}%")
        
        optimizations = []
        
        # Optimisations selon stats GPU
        if vram_usage > 80:
            optimizations.append("R√©duction batch_size pour limiter VRAM")
            optimization_applied = True
        elif vram_usage < 40:
            optimizations.append("Augmentation batch_size pour utiliser VRAM")
            optimization_applied = True
        
        if gpu_utilization < 50:
            optimizations.append("Augmentation parall√©lisme GPU")
            optimization_applied = True
        elif gpu_utilization > 95:
            optimizations.append("Throttling pour √©viter thermal throttling")
            optimization_applied = True
        
        # Optimisations sp√©cifiques workload
        if workload_type == 'molecular_analysis':
            optimizations.append("Configuration pipeline mol√©culaire")
            optimization_applied = True
        elif workload_type == 'corpus_processing':
            optimizations.append("Configuration traitement corpus intensif")
            optimization_applied = True
        elif workload_type == 'synthesis_validation':
            optimizations.append("Configuration validation parall√®le")
            optimization_applied = True
        
        if optimizations:
            for opt in optimizations:
                self.log(f"‚ö° {opt}")
        else:
            self.log("‚úÖ Configuration GPU optimale")
        
        return optimization_applied
    
    def run_panini_with_gpu_optimization(self):
        """Ex√©cute PaniniFS avec optimisation GPU temps r√©el"""
        self.log("üöÄ D√âMARRAGE PANINI + GPU OPTIMISATION")
        self.log("="*50)
        
        # D√©marrage monitoring
        self.start_gpu_monitoring_thread()
        time.sleep(2)  # Temps pour initialisation
        
        try:
            # Cycles d'optimisation + ex√©cution
            for cycle in range(3):
                self.log(f"\nüîÑ Cycle {cycle + 1}/3")
                
                # Statistiques GPU avant
                pre_stats = self.get_current_gpu_stats()
                self.log(f"üìä Pr√©-exec - VRAM: {pre_stats.get('vram_usage_percent', 0):.1f}% | GPU: {pre_stats.get('gpu_utilization', 0):.1f}%")
                
                # Optimisation dynamique
                workload = ['molecular_analysis', 'corpus_processing', 'synthesis_validation'][cycle]
                self.optimize_gpu_for_workload(workload)
                
                # Ex√©cution PaniniFS GPU-optimis√©
                self.log(f"üéØ Ex√©cution workload: {workload}")
                self.execute_panini_workload(workload)
                
                # Statistiques GPU apr√®s
                post_stats = self.get_current_gpu_stats()
                self.log(f"üìä Post-exec - VRAM: {post_stats.get('vram_usage_percent', 0):.1f}% | GPU: {post_stats.get('gpu_utilization', 0):.1f}%")
                
                # Pause entre cycles
                if cycle < 2:
                    self.log("‚è∏Ô∏è Pause inter-cycles...")
                    time.sleep(3)
            
            # R√©sum√© final
            self.print_final_summary()
            
        except KeyboardInterrupt:
            self.log("‚ö†Ô∏è Interruption utilisateur")
        except Exception as e:
            self.log(f"‚ùå Erreur ex√©cution: {e}")
        finally:
            self.running = False
            self.log("üèÅ Int√©grateur GPU arr√™t√©")
    
    def execute_panini_workload(self, workload_type):
        """Ex√©cute workload PaniniFS sp√©cifique"""
        start_time = time.time()
        
        try:
            # Ex√©cution pipeline GPU-optimis√©
            cmd = ['python3', 'gpu_accelerated_panini.py']
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=self.workspace
            )
            
            # Monitoring ex√©cution avec timeout
            try:
                stdout, stderr = process.communicate(timeout=30)
                
                if process.returncode == 0:
                    # Extraction m√©triques de performance
                    lines = stdout.split('\n')
                    atoms_processed = 0
                    molecules_synthesized = 0
                    processing_time = 0
                    
                    for line in lines:
                        if 'Atomes trait√©s:' in line:
                            try:
                                atoms_processed = int(line.split(':')[1].replace(',', '').strip())
                            except:
                                pass
                        elif 'Mol√©cules synth√©tis√©es:' in line:
                            try:
                                molecules_synthesized = int(line.split(':')[1].replace(',', '').strip())
                            except:
                                pass
                        elif 'Temps total:' in line:
                            try:
                                processing_time = float(line.split(':')[1].replace('s', '').strip())
                            except:
                                pass
                    
                    execution_time = time.time() - start_time
                    
                    # Performance metrics
                    self.log(f"‚úÖ Workload {workload_type} termin√©")
                    self.log(f"‚öõÔ∏è Atomes: {atoms_processed:,} | üß™ Mol√©cules: {molecules_synthesized:,}")
                    self.log(f"‚è±Ô∏è Temps pipeline: {processing_time:.2f}s | Total: {execution_time:.2f}s")
                    
                    if atoms_processed > 0 and processing_time > 0:
                        throughput = atoms_processed / processing_time
                        self.log(f"üöÄ D√©bit: {throughput:.0f} atomes/sec")
                
                else:
                    self.log(f"‚ùå Erreur ex√©cution (code {process.returncode})")
                    if stderr:
                        self.log(f"Erreur: {stderr[:200]}")
            
            except subprocess.TimeoutExpired:
                process.kill()
                self.log("‚è∞ Timeout ex√©cution workload")
        
        except Exception as e:
            self.log(f"‚ùå Erreur workload {workload_type}: {e}")
    
    def print_final_summary(self):
        """Affiche r√©sum√© final"""
        final_stats = self.get_current_gpu_stats()
        
        print("\n" + "="*60)
        print("üéÆ R√âSUM√â INT√âGRATEUR GPU + PANINI")
        print("="*60)
        print(f"üñ•Ô∏è √âtat GPU final:")
        print(f"   VRAM: {final_stats.get('vram_usage_percent', 0):.1f}%")
        print(f"   Utilisation: {final_stats.get('gpu_utilization', 0):.1f}%")
        print(f"üîß Optimisations appliqu√©es: 3 cycles")
        print(f"‚ö° Workloads ex√©cut√©s: molecular_analysis, corpus_processing, synthesis_validation")
        print(f"üìä Monitoring: {len(self.gpu_stats)} m√©triques collect√©es")
        print("="*60)
        print("‚úÖ Int√©gration GPU + PaniniFS compl√®te!")
        print("üìÅ R√©sultats d√©taill√©s dans gpu_accelerated_results/")
        print("="*60)


def main():
    print("üéÆ INT√âGRATEUR FINAL GPU + PANINI")
    print("="*40)
    print("Monitoring temps r√©el + Optimisations adaptatives")
    print("Pipeline complet avec feedback GPU")
    print("="*40)
    
    integrator = PaniniGPUIntegrator()
    integrator.run_panini_with_gpu_optimization()


if __name__ == '__main__':
    main()