#!/usr/bin/env python3
"""
SYST√àME DE MARQUEURS ONOMASTIQUES - Pipeline v7.3 Enhanced

Syst√®me de balisage sp√©cialis√© pour isoler les noms propres et leurs analyses
s√©mantiques du flux principal de traitement linguistique.

Principe : Les noms propres sont encapsul√©s dans des marqueurs sp√©ciaux
qui pr√©servent l'analyse onomastique sans interf√©rer avec le traitement
s√©mantique du reste de l'√©nonc√©.
"""

import re
import json
import time
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import uuid

@dataclass
class MarqueurOnomastique:
    """Marqueur sp√©cialis√© pour un nom propre"""
    id_marqueur: str  # UUID unique du marqueur
    nom_original: str  # Nom propre original
    type_onomastique: str  # anthroponyme, toponyme, taxonyme
    marqueur_ouverture: str  # Balise d'ouverture
    marqueur_fermeture: str  # Balise de fermeture
    contenu_semantique_isole: Dict[str, Any]  # Analyse compl√®te isol√©e
    position_debut: int  # Position dans le texte original
    position_fin: int  # Position de fin
    langue_detectee: str
    
    # M√©tadonn√©es de s√©paration
    niveau_isolation: str  # "complet", "partiel", "minimal"
    interference_possible: bool  # Si le marqueur peut interf√©rer
    priorite_traitement: int  # Ordre de traitement (1=priority)

@dataclass
class TexteAvecMarqueurs:
    """Texte avec marqueurs onomastiques int√©gr√©s"""
    texte_original: str
    texte_avec_marqueurs: str
    texte_semantique_pur: str  # Sans les noms propres
    marqueurs_onomastiques: List[MarqueurOnomastique]
    mapping_positions: Dict[str, Tuple[int, int]]  # id_marqueur -> (debut, fin)
    
    # Statistiques de s√©paration
    nombre_noms_marques: int
    pourcentage_contenu_onomastique: float
    pourcentage_contenu_semantique: float

class GestionnaireMarqueursOnomastiques:
    """Gestionnaire des marqueurs onomastiques"""
    
    def __init__(self):
        self.version = "v7.3-Marqueurs"
        self.timestamp_init = datetime.now().isoformat()
        
        # Configuration des marqueurs
        self.config_marqueurs = {
            "anthroponyme": {
                "prefixe": "‚ü®üë§",
                "suffixe": "üë§‚ü©",
                "classe": "PERS",
                "couleur_debug": "\033[94m"  # Bleu
            },
            "toponyme": {
                "prefixe": "‚ü®üó∫Ô∏è",
                "suffixe": "üó∫Ô∏è‚ü©",
                "classe": "LIEU",
                "couleur_debug": "\033[92m"  # Vert
            },
            "taxonyme": {
                "prefixe": "‚ü®üî¨",
                "suffixe": "üî¨‚ü©",
                "classe": "TAXO",
                "couleur_debug": "\033[93m"  # Jaune
            },
            "inconnu": {
                "prefixe": "‚ü®‚ùì",
                "suffixe": "‚ùì‚ü©",
                "classe": "UNKN",
                "couleur_debug": "\033[91m"  # Rouge
            }
        }
        
        # Patterns de reconnaissance
        self.patterns_protection = {
            "debut_phrase": r'^[A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û]',
            "nom_propre": r'\b[A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û][a-z√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø]*\b',
            "nom_compose": r'[A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û][a-z√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø]*[-\'][A-Z√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√ûA-z√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø]*',
            "titre_honorifique": r'\b(Dr|Mr|Mrs|Ms|Prof|St|Ste)\.'
        }
        
        print(f"üè∑Ô∏è Gestionnaire Marqueurs Onomastiques {self.version} initialis√©")
        print(f"üéØ Marqueurs configur√©s : {len(self.config_marqueurs)} types")
    
    def traiter_phrase_avec_marqueurs(self, phrase: str, langue: str, 
                                    contexte_locuteur: str = "inconnu") -> TexteAvecMarqueurs:
        """Traite une phrase en ajoutant les marqueurs onomastiques"""
        
        print(f"\nüè∑Ô∏è MARQUAGE ONOMASTIQUE : '{phrase}'")
        print(f"üåç Langue: {langue} | üë§ Locuteur: {contexte_locuteur}")
        print("-" * 70)
        
        debut = time.time()
        
        # D√©tection des noms propres avec positions
        noms_detectes = self._detecter_noms_avec_positions(phrase)
        print(f"üìã Noms d√©tect√©s : {[(nom, pos) for nom, pos, _ in noms_detectes]}")
        
        # Cr√©ation des marqueurs
        marqueurs = []
        texte_avec_marqueurs = phrase
        offset_position = 0
        
        for nom, position_debut, position_fin in noms_detectes:
            marqueur = self._creer_marqueur_onomastique(
                nom, position_debut + offset_position, langue, contexte_locuteur
            )
            marqueurs.append(marqueur)
            
            # Remplacement dans le texte
            avant = texte_avec_marqueurs[:position_debut + offset_position]
            apres = texte_avec_marqueurs[position_fin + offset_position:]
            
            texte_remplace = f"{marqueur.marqueur_ouverture}{nom}{marqueur.marqueur_fermeture}"
            texte_avec_marqueurs = avant + texte_remplace + apres
            
            # Mise √† jour de l'offset
            offset_position += len(texte_remplace) - len(nom)
        
        # Cr√©ation du texte s√©mantique pur (sans noms propres)
        texte_semantique_pur = self._creer_texte_semantique_pur(phrase, noms_detectes)
        
        # Mapping des positions
        mapping_positions = self._creer_mapping_positions(marqueurs, texte_avec_marqueurs)
        
        # Statistiques
        stats = self._calculer_statistiques_separation(phrase, marqueurs)
        
        resultat = TexteAvecMarqueurs(
            texte_original=phrase,
            texte_avec_marqueurs=texte_avec_marqueurs,
            texte_semantique_pur=texte_semantique_pur,
            marqueurs_onomastiques=marqueurs,
            mapping_positions=mapping_positions,
            nombre_noms_marques=len(marqueurs),
            pourcentage_contenu_onomastique=stats["onomastique"],
            pourcentage_contenu_semantique=stats["semantique"]
        )
        
        temps_total = (time.time() - debut) * 1000
        self._afficher_resultat_marquage(resultat, temps_total)
        
        return resultat
    
    def _detecter_noms_avec_positions(self, phrase: str) -> List[Tuple[str, int, int]]:
        """D√©tecte les noms propres avec leurs positions exactes"""
        noms_avec_positions = []
        
        # Pattern principal pour noms propres
        for match in re.finditer(self.patterns_protection["nom_propre"], phrase):
            nom = match.group()
            debut = match.start()
            fin = match.end()
            
            # Filtrage intelligent
            if self._est_vraiment_nom_propre(nom, debut, phrase):
                noms_avec_positions.append((nom, debut, fin))
        
        # Pattern pour noms compos√©s
        for match in re.finditer(self.patterns_protection["nom_compose"], phrase):
            nom = match.group()
            debut = match.start()
            fin = match.end()
            
            if self._est_vraiment_nom_propre(nom, debut, phrase):
                noms_avec_positions.append((nom, debut, fin))
        
        # Pattern pour titres honorifiques
        for match in re.finditer(self.patterns_protection["titre_honorifique"], phrase):
            nom = match.group()
            debut = match.start()
            fin = match.end()
            noms_avec_positions.append((nom, debut, fin))
        
        # Suppression des doublons et tri par position
        noms_uniques = list(set(noms_avec_positions))
        return sorted(noms_uniques, key=lambda x: x[1])
    
    def _est_vraiment_nom_propre(self, nom: str, position: int, phrase: str) -> bool:
        """D√©termine si c'est vraiment un nom propre ou juste d√©but de phrase"""
        
        # Si c'est au d√©but de phrase, v√©rification suppl√©mentaire
        if position == 0:
            # Liste des mots courants qui ne sont pas des noms propres
            mots_non_propres = {
                'fr': ['Un', 'Une', 'Le', 'La', 'Les', 'Ce', 'Cette', 'Il', 'Elle', 'Ils', 'Elles'],
                'en': ['The', 'A', 'An', 'This', 'That', 'It', 'He', 'She', 'They'],
                'de': ['Der', 'Die', 'Das', 'Ein', 'Eine', 'Es', 'Er', 'Sie']
            }
            
            # Si le mot est dans la liste des non-propres, ce n'est pas un nom propre
            for langue, liste in mots_non_propres.items():
                if nom in liste:
                    return False
        
        # Autres heuristiques
        if len(nom) < 2:
            return False
        
        if nom in ['Dr', 'Mr', 'Mrs', 'Ms', 'Prof', 'St', 'Ste']:
            return True  # Titres honorifiques
        
        return True  # Par d√©faut, consid√©rer comme nom propre
    
    def _creer_marqueur_onomastique(self, nom: str, position: int, langue: str, 
                                  contexte: str) -> MarqueurOnomastique:
        """Cr√©e un marqueur onomastique pour un nom"""
        
        # G√©n√©ration d'un ID unique
        id_marqueur = f"ONO_{uuid.uuid4().hex[:8].upper()}"
        
        # D√©termination du type onomastique
        type_ono = self._determiner_type_onomastique_simple(nom)
        
        # Configuration du marqueur
        config = self.config_marqueurs.get(type_ono, self.config_marqueurs["inconnu"])
        
        # Analyse s√©mantique isol√©e (version simplifi√©e)
        contenu_isole = self._analyser_semantique_isole(nom, type_ono, langue)
        
        # Cr√©ation du marqueur
        marqueur_ouv = f"{config['prefixe']}#{id_marqueur}:"
        marqueur_ferm = f":{config['classe']}#{config['suffixe']}"
        
        return MarqueurOnomastique(
            id_marqueur=id_marqueur,
            nom_original=nom,
            type_onomastique=type_ono,
            marqueur_ouverture=marqueur_ouv,
            marqueur_fermeture=marqueur_ferm,
            contenu_semantique_isole=contenu_isole,
            position_debut=position,
            position_fin=position + len(nom),
            langue_detectee=langue,
            niveau_isolation="complet",
            interference_possible=False,
            priorite_traitement=1
        )
    
    def _determiner_type_onomastique_simple(self, nom: str) -> str:
        """D√©termine le type onomastique de fa√ßon simplifi√©e"""
        
        # Bases de donn√©es simplifi√©es
        anthroponymes_courants = {
            'fr': ['Jean', 'Marie', 'Pierre', 'Paul', 'Jacques', 'Fran√ßois', 'Louis', '√âsope'],
            'en': ['John', 'Mary', 'James', 'Smith', 'Johnson', 'Williams', 'Brown', 'Dr'],
            'de': ['Hans', 'Anna', 'Klaus', 'Grete', 'Wolfgang', 'Schmidt', 'Mueller']
        }
        
        toponymes_courants = {
            'fr': ['Paris', 'Lyon', 'Marseille', 'France', 'Europe', 'Berlin'],
            'en': ['London', 'Paris', 'New York', 'Europe', 'America', 'Africa'],
            'de': ['Berlin', 'M√ºnchen', 'Hamburg', 'Deutschland', 'Europa']
        }
        
        taxonymes_courants = ['Homo', 'Quercus', 'Felis', 'Rosa', 'Canis']
        
        # Classification
        for langue, liste in anthroponymes_courants.items():
            if nom in liste:
                return "anthroponyme"
        
        for langue, liste in toponymes_courants.items():
            if nom in liste:
                return "toponyme"
        
        if nom in taxonymes_courants:
            return "taxonyme"
        
        # Heuristiques
        if nom.endswith(('us', 'a', 'um')):
            return "taxonyme"
        elif len(nom) > 6:
            return "toponyme"
        else:
            return "anthroponyme"
    
    def _analyser_semantique_isole(self, nom: str, type_ono: str, langue: str) -> Dict[str, Any]:
        """Analyse s√©mantique isol√©e dans le marqueur"""
        
        # DhƒÅtu simplifi√©s selon le type
        dhatus_par_type = {
            "anthroponyme": ["EXIST", "COMMUNICATE"],
            "toponyme": ["SPACE", "EXIST", "COMMUNICATE"],
            "taxonyme": ["QUALITY", "EXIST"]
        }
        
        return {
            "dhatus_associes": dhatus_par_type.get(type_ono, ["EXIST"]),
            "representation_universelle": f"{'+'.join(dhatus_par_type.get(type_ono, ['EXIST']))}[{nom}]",
            "niveau_analyse": "basique",
            "necessite_approfondissement": True,
            "timestamp_isolation": datetime.now().isoformat()
        }
    
    def _creer_texte_semantique_pur(self, phrase: str, noms_detectes: List[Tuple[str, int, int]]) -> str:
        """Cr√©e un texte s√©mantique pur sans les noms propres"""
        
        texte_pur = phrase
        
        # Remplacement des noms par des placeholders s√©mantiques
        for nom, debut, fin in reversed(noms_detectes):  # Ordre inverse pour pr√©server positions
            type_ono = self._determiner_type_onomastique_simple(nom)
            
            placeholders = {
                "anthroponyme": "[INDIVIDU]",
                "toponyme": "[LIEU]",
                "taxonyme": "[ESP√àCE]",
                "inconnu": "[ENTIT√â]"
            }
            
            placeholder = placeholders.get(type_ono, "[ENTIT√â]")
            texte_pur = texte_pur[:debut] + placeholder + texte_pur[fin:]
        
        return texte_pur
    
    def _creer_mapping_positions(self, marqueurs: List[MarqueurOnomastique], 
                               texte_marque: str) -> Dict[str, Tuple[int, int]]:
        """Cr√©e un mapping des positions des marqueurs"""
        mapping = {}
        
        for marqueur in marqueurs:
            # Recherche de la position du marqueur dans le texte marqu√©
            pattern = re.escape(marqueur.marqueur_ouverture)
            match = re.search(pattern, texte_marque)
            if match:
                debut = match.start()
                fin = debut + len(marqueur.marqueur_ouverture) + len(marqueur.nom_original) + len(marqueur.marqueur_fermeture)
                mapping[marqueur.id_marqueur] = (debut, fin)
        
        return mapping
    
    def _calculer_statistiques_separation(self, phrase: str, 
                                        marqueurs: List[MarqueurOnomastique]) -> Dict[str, float]:
        """Calcule les statistiques de s√©paration"""
        
        longueur_totale = len(phrase)
        longueur_noms = sum(len(m.nom_original) for m in marqueurs)
        
        pourcentage_onomastique = (longueur_noms / longueur_totale) * 100 if longueur_totale > 0 else 0
        pourcentage_semantique = 100 - pourcentage_onomastique
        
        return {
            "onomastique": pourcentage_onomastique,
            "semantique": pourcentage_semantique
        }
    
    def _afficher_resultat_marquage(self, resultat: TexteAvecMarqueurs, temps_ms: float):
        """Affiche le r√©sultat du marquage"""
        
        print(f"\nüìä R√âSULTAT DU MARQUAGE")
        print(f"‚è±Ô∏è Temps: {temps_ms:.2f}ms")
        print(f"üî¢ Noms marqu√©s: {resultat.nombre_noms_marques}")
        print(f"üìà Contenu onomastique: {resultat.pourcentage_contenu_onomastique:.1f}%")
        print(f"üìà Contenu s√©mantique: {resultat.pourcentage_contenu_semantique:.1f}%")
        
        print(f"\nüìù TEXTE ORIGINAL:")
        print(f"   {resultat.texte_original}")
        
        print(f"\nüè∑Ô∏è TEXTE AVEC MARQUEURS:")
        print(f"   {resultat.texte_avec_marqueurs}")
        
        print(f"\nüß† TEXTE S√âMANTIQUE PUR:")
        print(f"   {resultat.texte_semantique_pur}")
        
        print(f"\nüìã MARQUEURS CR√â√âS:")
        for i, marqueur in enumerate(resultat.marqueurs_onomastiques, 1):
            print(f"   {i}. {marqueur.id_marqueur} : '{marqueur.nom_original}' "
                  f"({marqueur.type_onomastique})")
            print(f"      DhƒÅtu: {' + '.join(marqueur.contenu_semantique_isole['dhatus_associes'])}")
            print(f"      Isolation: {marqueur.niveau_isolation}")
    
    def extraire_nom_depuis_marqueur(self, texte_marque: str, id_marqueur: str) -> Optional[str]:
        """Extrait un nom depuis son marqueur"""
        
        # Pattern pour extraire le contenu d'un marqueur sp√©cifique
        pattern = rf"‚ü®[^‚ü©]*#{id_marqueur}:([^:]+):[^‚ü©]*‚ü©"
        match = re.search(pattern, texte_marque)
        
        return match.group(1) if match else None
    
    def reconstituer_texte_original(self, texte_marque: str) -> str:
        """Reconstitue le texte original depuis la version marqu√©e"""
        
        # Pattern pour tous les marqueurs
        pattern = r"‚ü®[^‚ü©]*#[^:]+:([^:]+):[^‚ü©]*‚ü©"
        
        def remplacer_marqueur(match):
            return match.group(1)  # Retourne juste le nom
        
        return re.sub(pattern, remplacer_marqueur, texte_marque)


def test_marqueurs_onomastiques():
    """Test du syst√®me de marqueurs onomastiques"""
    print("üß™ TEST DU SYST√àME DE MARQUEURS ONOMASTIQUES")
    print("=" * 80)
    
    gestionnaire = GestionnaireMarqueursOnomastiques()
    
    # Phrases de test
    phrases_test = [
        ("Dr. Smith's cat‚Äîwhat a story!", "en", "narrateur_moderne"),
        ("√âsope racontait ses fables √† Paris.", "fr", "conteur_traditionnel"),
        ("Marie et Jean visitent Berlin chaque √©t√©.", "fr", "narrateur_quotidien"),
        ("The species Homo sapiens evolved in Africa.", "en", "scientifique")
    ]
    
    for phrase, langue, contexte in phrases_test:
        print(f"\n" + "="*80)
        
        resultat = gestionnaire.traiter_phrase_avec_marqueurs(phrase, langue, contexte)
        
        # Test de reconstitution
        print(f"\nüîÑ TEST DE RECONSTITUTION:")
        texte_reconstitue = gestionnaire.reconstituer_texte_original(resultat.texte_avec_marqueurs)
        print(f"   Original    : {resultat.texte_original}")
        print(f"   Reconstitu√© : {texte_reconstitue}")
        print(f"   Identique   : {'‚úÖ' if texte_reconstitue == resultat.texte_original else '‚ùå'}")
        
        # Sauvegarde
        nom_fichier = f"marquage_onomastique_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{langue}.json"
        with open(nom_fichier, 'w', encoding='utf-8') as f:
            resultat_dict = asdict(resultat)
            json.dump(resultat_dict, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Marquage sauvegard√©: {nom_fichier}")


if __name__ == "__main__":
    test_marqueurs_onomastiques()